{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Statistical methods (Z-Score, IQR, Mahalanobis)\n",
    "- Isolation Forest\n",
    "- Local Outlier Factor (LOF)\n",
    "- One-Class SVM\n",
    "- Ensemble anomaly detection\n",
    "- Time series anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "np.random.seed(42)\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Data with Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal, _ = make_blobs(n_samples=1000, centers=2, cluster_std=1.0, random_state=42)\n",
    "X_anomaly = np.random.uniform(-8, 8, (50, 2))\n",
    "X_all = np.vstack([X_normal, X_anomaly])\n",
    "y_true = np.concatenate([np.ones(1000), -np.ones(50)])  # 1=normal, -1=anomaly\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_normal[:, 0], X_normal[:, 1], c='blue', s=10, alpha=0.5, label='Normal')\n",
    "plt.scatter(X_anomaly[:, 0], X_anomaly[:, 1], c='red', s=30, marker='x', label='Anomaly')\n",
    "plt.legend(); plt.title('Data with Anomalies'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Why: Isolation Forest detects anomalies by measuring how few random splits are needed\n# to isolate a point — anomalies sit in sparse regions and are isolated quickly (short\n# path length), while normal points in dense clusters require many splits.\n# contamination=0.05 tells the model to expect ~5% of points to be anomalous.\niso = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\ny_iso = iso.fit_predict(X_all)\nscores = iso.decision_function(X_all)\n\n# Score contour\nxx, yy = np.meshgrid(np.linspace(-10, 10, 100), np.linspace(-10, 10, 100))\nZ = iso.decision_function(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax.contourf(xx, yy, Z, levels=20, cmap='RdBu')\nax.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\nc = ['red' if p == -1 else 'blue' for p in y_iso]\nax.scatter(X_all[:, 0], X_all[:, 1], c=c, s=15, alpha=0.6, edgecolors='k', linewidths=0.3)\nax.set_title(f'Isolation Forest ({(y_iso==-1).sum()} anomalies)')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Why: LOF measures how much denser a point's neighbors are compared to the point itself.\n# n_neighbors=20 defines the locality — too small and it's noise-sensitive, too large\n# and it loses the ability to detect local anomalies in varying-density data.\nlof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\ny_lof = lof.fit_predict(X_all)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfor ax, preds, name in zip(axes, [y_iso, y_lof], ['Isolation Forest', 'LOF']):\n    c = ['red' if p == -1 else 'blue' for p in preds]\n    ax.scatter(X_all[:, 0], X_all[:, 1], c=c, s=15, alpha=0.6)\n    ax.set_title(f'{name} ({(preds==-1).sum()} anomalies)')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "y_true_bin = (y_true == -1).astype(int)\n\n# Why: One-Class SVM learns a boundary around normal data in kernel space. Scaling is\n# critical here because the RBF kernel uses Euclidean distance — unscaled features\n# would skew the boundary. nu=0.05 upper-bounds the anomaly fraction.\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_all)\nocsvm = OneClassSVM(kernel='rbf', gamma='scale', nu=0.05)\ny_svm = ocsvm.fit_predict(X_scaled)\n\nresults = {}\nfor name, preds in [('IsolationForest', y_iso), ('LOF', y_lof), ('OneClassSVM', y_svm)]:\n    p_bin = (preds == -1).astype(int)\n    results[name] = {\n        'Detected': p_bin.sum(),\n        'Precision': precision_score(y_true_bin, p_bin),\n        'Recall': recall_score(y_true_bin, p_bin),\n        'F1': f1_score(y_true_bin, p_bin)\n    }\n\npd.DataFrame(results).T.round(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Series Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "n = 500\nt = np.arange(n)\nts = 50 + 5 * np.sin(2 * np.pi * t / 100) + np.random.normal(0, 2, n)\nfor idx in [100, 200, 300, 400]:\n    ts[idx] += np.random.choice([-1, 1]) * 20\n\nts_df = pd.DataFrame({'value': ts})\n# Why: A rolling z-score adapts to local trends and seasonality — it compares each point\n# to its recent history rather than the global mean, which is essential for non-stationary\n# time series where the baseline shifts over time.\nwindow = 30\nts_df['roll_mean'] = ts_df['value'].rolling(window).mean()\nts_df['roll_std'] = ts_df['value'].rolling(window).std()\nts_df['z'] = (ts_df['value'] - ts_df['roll_mean']) / ts_df['roll_std']\nts_df['anomaly'] = ts_df['z'].abs() > 3\n\nfig, ax = plt.subplots(figsize=(14, 5))\nax.plot(ts_df['value'], 'b-', alpha=0.7, lw=0.8)\nax.plot(ts_df['roll_mean'], 'g-', lw=1.5)\nax.fill_between(range(n), ts_df['roll_mean']-3*ts_df['roll_std'],\n                ts_df['roll_mean']+3*ts_df['roll_std'], alpha=0.2, color='green')\nanom = ts_df[ts_df['anomaly']]\nax.scatter(anom.index, anom['value'], c='red', s=60, zorder=5, label=f'{len(anom)} anomalies')\nax.set_title('Rolling Z-Score Anomaly Detection'); ax.legend()\nplt.tight_layout(); plt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}