{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Machine Learning\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Converting time series to supervised learning\n",
    "- Feature engineering (lags, rolling, calendar, Fourier)\n",
    "- TimeSeriesSplit cross-validation\n",
    "- Tree-based forecasting (GradientBoosting)\n",
    "- Walk-forward backtesting\n",
    "- Time series classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n",
    "\n",
    "np.random.seed(42)\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 730\n",
    "dates = pd.date_range('2022-01-01', periods=n_days, freq='D')\n",
    "trend = np.linspace(100, 150, n_days)\n",
    "weekly = 15 * np.sin(2 * np.pi * np.arange(n_days) / 7)\n",
    "yearly = 30 * np.sin(2 * np.pi * np.arange(n_days) / 365.25)\n",
    "noise = np.random.normal(0, 5, n_days)\n",
    "sales = trend + weekly + yearly + noise\n",
    "\n",
    "df = pd.DataFrame({'date': dates, 'sales': sales})\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(df['date'], df['sales'], linewidth=0.8)\n",
    "plt.title('Daily Sales (2 years)')\n",
    "plt.xlabel('Date'); plt.ylabel('Sales')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag features\n",
    "for lag in [1, 7, 14, 28, 365]:\n",
    "    df[f'lag_{lag}'] = df['sales'].shift(lag)\n",
    "\n",
    "# Rolling features (shift to prevent leakage)\n",
    "for w in [7, 14, 30]:\n",
    "    shifted = df['sales'].shift(1)\n",
    "    df[f'roll_mean_{w}'] = shifted.rolling(w).mean()\n",
    "    df[f'roll_std_{w}'] = shifted.rolling(w).std()\n",
    "\n",
    "# Calendar features\n",
    "df['dow'] = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n",
    "df['is_weekend'] = df['date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "# Cyclical encoding\n",
    "df['dow_sin'] = np.sin(2 * np.pi * df['dow'] / 7)\n",
    "df['dow_cos'] = np.cos(2 * np.pi * df['dow'] / 7)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# Fourier features for yearly seasonality\n",
    "t = np.arange(len(df))\n",
    "for k in range(1, 4):\n",
    "    df[f'year_sin_{k}'] = np.sin(2 * np.pi * k * t / 365.25)\n",
    "    df[f'year_cos_{k}'] = np.cos(2 * np.pi * k * t / 365.25)\n",
    "\n",
    "print(f'Features created: {len(df.columns) - 2}')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f'Rows after dropping NaN: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TimeSeriesSplit Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [c for c in df.columns if c not in ['date', 'sales']]\n",
    "X = df[feat_cols]\n",
    "y = df['sales']\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "scores = cross_val_score(gb, X, y, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "print(f'TimeSeriesSplit MAE: {-scores.mean():.2f} (+/- {scores.std():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = len(X) - 60\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "dates_test = df['date'].iloc[split:]\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "print(f'MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.1f}%')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(dates_test, y_test, 'b-', label='Actual', lw=2)\n",
    "ax.plot(dates_test, y_pred, 'r--', label='Predicted', lw=2)\n",
    "ax.set_title(f'GB Forecast (MAE={mae:.2f})')\n",
    "ax.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "imp = pd.Series(gb.feature_importances_, index=feat_cols).nlargest(15)\n",
    "imp.sort_values().plot(kind='barh', figsize=(10, 6), color='steelblue')\n",
    "plt.title('Top 15 Features'); plt.xlabel('Importance')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Series Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_series, length = 300, 100\n",
    "X_ts, y_ts = [], []\n",
    "for _ in range(n_series):\n",
    "    label = np.random.choice([0, 1, 2])\n",
    "    t = np.arange(length)\n",
    "    if label == 0: s = np.cumsum(np.random.normal(0, 1, length))\n",
    "    elif label == 1: s = 0.5 * t + np.random.normal(0, 3, length)\n",
    "    else: s = 10 * np.sin(2 * np.pi * t / 20) + np.random.normal(0, 1, length)\n",
    "    X_ts.append(s); y_ts.append(label)\n",
    "\n",
    "X_ts = np.array(X_ts); y_ts = np.array(y_ts)\n",
    "\n",
    "# Extract features\n",
    "feats = pd.DataFrame([{\n",
    "    'mean': s.mean(), 'std': s.std(), 'trend': np.polyfit(range(len(s)), s, 1)[0],\n",
    "    'autocorr': pd.Series(s).autocorr(1), 'crossing': np.mean(np.diff(np.sign(s - s.mean())) != 0),\n",
    "    'skew': pd.Series(s).skew(), 'kurtosis': pd.Series(s).kurtosis()\n",
    "} for s in X_ts])\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(feats, y_ts, test_size=0.3, random_state=42)\n",
    "clf = RandomForestClassifier(100, random_state=42)\n",
    "clf.fit(Xtr, ytr)\n",
    "print(classification_report(yte, clf.predict(Xte), target_names=['Stationary','Trending','Seasonal']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.9.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
