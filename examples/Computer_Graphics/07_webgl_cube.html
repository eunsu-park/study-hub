<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGL 3D Cube with Phong Lighting</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            background: #0f0f1a;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            font-family: 'Segoe UI', system-ui, sans-serif;
            color: #d0d0d0;
        }
        canvas {
            border: 1px solid #333;
            border-radius: 4px;
            cursor: grab;
        }
        canvas:active { cursor: grabbing; }
        h1 { margin-bottom: 10px; font-size: 20px; font-weight: 500; }
        .controls {
            margin-top: 10px;
            text-align: center;
            font-size: 13px;
            line-height: 1.6;
            opacity: 0.7;
        }
    </style>
</head>
<body>
    <h1>WebGL: Phong-Lit 3D Cube</h1>
    <canvas id="glcanvas" width="700" height="700"></canvas>
    <div class="controls">
        Drag to orbit &bull; Scroll / Arrow Up/Down to zoom &bull;
        W/A/S/D to move light &bull; R to reset
    </div>

<script>
/*
 * WebGL 3D Cube with Phong Lighting
 * ===================================
 *
 * Builds on 06_webgl_triangle.html with:
 * 1. 3D cube geometry (vertices, normals, face colors)
 * 2. Model-View-Projection matrices in JavaScript
 * 3. Phong lighting computed in the fragment shader
 * 4. Mouse drag orbit camera
 * 5. Keyboard controls for zoom and light position
 *
 * This example is the "hello world" of 3D WebGL -- getting a properly
 * lit, interactive 3D object on screen.
 */

// =========================================================================
// 1. Shaders
// =========================================================================

const VS_SOURCE = `
    attribute vec3 a_position;
    attribute vec3 a_normal;
    attribute vec3 a_color;

    uniform mat4 u_model;
    uniform mat4 u_view;
    uniform mat4 u_projection;
    // Normal matrix: inverse transpose of model matrix
    // Why not just u_model?  Non-uniform scaling distorts normals.
    // The normal matrix corrects for this.  For uniform scaling and
    // pure rotations they're equivalent, but using the normal matrix
    // is the correct general approach.
    uniform mat3 u_normalMatrix;

    varying vec3 v_worldPos;
    varying vec3 v_normal;
    varying vec3 v_color;

    void main() {
        // Transform position to world space for lighting calculations
        vec4 worldPos = u_model * vec4(a_position, 1.0);
        v_worldPos = worldPos.xyz;

        // Transform normal to world space
        v_normal = normalize(u_normalMatrix * a_normal);

        v_color = a_color;

        // Final clip-space position: P * V * M * position
        gl_Position = u_projection * u_view * worldPos;
    }
`;

const FS_SOURCE = `
    precision mediump float;

    varying vec3 v_worldPos;
    varying vec3 v_normal;
    varying vec3 v_color;

    uniform vec3 u_lightPos;
    uniform vec3 u_viewPos;

    void main() {
        // Phong illumination computed per-fragment (Phong shading)
        // Why per-fragment instead of per-vertex (Gouraud)?  Per-fragment
        // produces smoother, more accurate specular highlights, especially
        // on low-poly geometry like this cube.

        vec3 N = normalize(v_normal);
        vec3 L = normalize(u_lightPos - v_worldPos);
        vec3 V = normalize(u_viewPos - v_worldPos);
        vec3 R = reflect(-L, N);

        // Ambient: minimum base illumination
        float ambientStrength = 0.15;
        vec3 ambient = ambientStrength * v_color;

        // Diffuse: Lambert's cosine law
        float diff = max(dot(N, L), 0.0);
        vec3 diffuse = diff * v_color;

        // Specular: Phong model with shininess exponent
        // Why pow 32?  Higher values = tighter, more mirror-like highlights.
        // 32 gives a moderate glossy appearance suitable for a general demo.
        float spec = pow(max(dot(R, V), 0.0), 32.0);
        vec3 specular = 0.5 * spec * vec3(1.0, 1.0, 1.0);

        vec3 result = ambient + diffuse + specular;

        // Simple gamma correction for more natural appearance
        result = pow(result, vec3(1.0/2.2));

        gl_FragColor = vec4(result, 1.0);
    }
`;

// =========================================================================
// 2. Initialize WebGL
// =========================================================================

const canvas = document.getElementById('glcanvas');
const gl = canvas.getContext('webgl');

if (!gl) {
    document.body.innerHTML = '<h2>WebGL not supported</h2>';
    throw new Error('No WebGL');
}

gl.enable(gl.DEPTH_TEST);   // Enable Z-buffer for correct occlusion
gl.enable(gl.CULL_FACE);    // Cull back faces for performance
gl.clearColor(0.06, 0.06, 0.1, 1.0);

// =========================================================================
// 3. Shader compilation (reused from 06)
// =========================================================================

function compileShader(gl, type, source) {
    const shader = gl.createShader(type);
    gl.shaderSource(shader, source);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        console.error(gl.getShaderInfoLog(shader));
        gl.deleteShader(shader);
        return null;
    }
    return shader;
}

function createProgram(gl, vsSrc, fsSrc) {
    const vs = compileShader(gl, gl.VERTEX_SHADER, vsSrc);
    const fs = compileShader(gl, gl.FRAGMENT_SHADER, fsSrc);
    const prog = gl.createProgram();
    gl.attachShader(prog, vs);
    gl.attachShader(prog, fs);
    gl.linkProgram(prog);
    if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
        console.error(gl.getProgramInfoLog(prog));
        return null;
    }
    return prog;
}

const program = createProgram(gl, VS_SOURCE, FS_SOURCE);
gl.useProgram(program);

// Look up all locations at init time
const loc = {
    position:     gl.getAttribLocation(program, 'a_position'),
    normal:       gl.getAttribLocation(program, 'a_normal'),
    color:        gl.getAttribLocation(program, 'a_color'),
    model:        gl.getUniformLocation(program, 'u_model'),
    view:         gl.getUniformLocation(program, 'u_view'),
    projection:   gl.getUniformLocation(program, 'u_projection'),
    normalMatrix: gl.getUniformLocation(program, 'u_normalMatrix'),
    lightPos:     gl.getUniformLocation(program, 'u_lightPos'),
    viewPos:      gl.getUniformLocation(program, 'u_viewPos'),
};

// =========================================================================
// 4. Cube geometry
// =========================================================================

/*
 * Why 24 vertices instead of 8?  Each face needs its own normals for
 * correct lighting.  Vertex 0 of the front face has normal (0,0,1),
 * but vertex 0 of the left face needs normal (-1,0,0).  Since WebGL
 * doesn't support per-face data, we duplicate vertices so each has
 * the correct normal for its face.
 */

// prettier-ignore
const cubeData = {
    // 6 faces * 4 vertices = 24 vertices
    // Each vertex: position (3) + normal (3) + color (3) = 9 floats
    vertices: new Float32Array([
        // Front face (z = +1), normal = (0, 0, 1), color = coral red
        -1, -1,  1,   0,  0,  1,  0.95, 0.40, 0.35,
         1, -1,  1,   0,  0,  1,  0.95, 0.40, 0.35,
         1,  1,  1,   0,  0,  1,  0.95, 0.40, 0.35,
        -1,  1,  1,   0,  0,  1,  0.95, 0.40, 0.35,

        // Back face (z = -1), normal = (0, 0, -1), color = teal
        -1, -1, -1,   0,  0, -1,  0.30, 0.80, 0.75,
        -1,  1, -1,   0,  0, -1,  0.30, 0.80, 0.75,
         1,  1, -1,   0,  0, -1,  0.30, 0.80, 0.75,
         1, -1, -1,   0,  0, -1,  0.30, 0.80, 0.75,

        // Top face (y = +1), normal = (0, 1, 0), color = golden
         -1,  1, -1,  0,  1,  0,  0.95, 0.85, 0.35,
         -1,  1,  1,  0,  1,  0,  0.95, 0.85, 0.35,
          1,  1,  1,  0,  1,  0,  0.95, 0.85, 0.35,
          1,  1, -1,  0,  1,  0,  0.95, 0.85, 0.35,

        // Bottom face (y = -1), normal = (0, -1, 0), color = purple
        -1, -1, -1,   0, -1,  0,  0.60, 0.35, 0.85,
         1, -1, -1,   0, -1,  0,  0.60, 0.35, 0.85,
         1, -1,  1,   0, -1,  0,  0.60, 0.35, 0.85,
        -1, -1,  1,   0, -1,  0,  0.60, 0.35, 0.85,

        // Right face (x = +1), normal = (1, 0, 0), color = sky blue
         1, -1, -1,   1,  0,  0,  0.35, 0.65, 0.95,
         1,  1, -1,   1,  0,  0,  0.35, 0.65, 0.95,
         1,  1,  1,   1,  0,  0,  0.35, 0.65, 0.95,
         1, -1,  1,   1,  0,  0,  0.35, 0.65, 0.95,

        // Left face (x = -1), normal = (-1, 0, 0), color = lime
        -1, -1, -1,  -1,  0,  0,  0.50, 0.90, 0.40,
        -1, -1,  1,  -1,  0,  0,  0.50, 0.90, 0.40,
        -1,  1,  1,  -1,  0,  0,  0.50, 0.90, 0.40,
        -1,  1, -1,  -1,  0,  0,  0.50, 0.90, 0.40,
    ]),

    // Index buffer: 2 triangles per face, 6 faces = 36 indices
    // Why an index buffer?  It avoids duplicating vertex data for shared
    // vertices within a face.  Each quad (4 vertices) becomes 2 triangles
    // (6 indices), saving memory and bandwidth.
    indices: new Uint16Array([
         0,  1,  2,   0,  2,  3,  // front
         4,  5,  6,   4,  6,  7,  // back
         8,  9, 10,   8, 10, 11,  // top
        12, 13, 14,  12, 14, 15,  // bottom
        16, 17, 18,  16, 18, 19,  // right
        20, 21, 22,  20, 22, 23,  // left
    ]),
};

// Upload vertex data
const vbo = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, vbo);
gl.bufferData(gl.ARRAY_BUFFER, cubeData.vertices, gl.STATIC_DRAW);

// Upload index data
const ebo = gl.createBuffer();
gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, ebo);
gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, cubeData.indices, gl.STATIC_DRAW);

// Set up vertex attribute pointers
const STRIDE = 9 * 4; // 9 floats * 4 bytes
gl.enableVertexAttribArray(loc.position);
gl.vertexAttribPointer(loc.position, 3, gl.FLOAT, false, STRIDE, 0);
gl.enableVertexAttribArray(loc.normal);
gl.vertexAttribPointer(loc.normal, 3, gl.FLOAT, false, STRIDE, 3 * 4);
gl.enableVertexAttribArray(loc.color);
gl.vertexAttribPointer(loc.color, 3, gl.FLOAT, false, STRIDE, 6 * 4);

// =========================================================================
// 5. Matrix math (minimal, no library)
// =========================================================================

/*
 * Why implement matrices by hand?  For learning, seeing the actual math
 * is more valuable than using gl-matrix.  Each function maps directly
 * to a concept from 02_transformations_3d.py.
 *
 * All matrices are stored in column-major order (WebGL convention).
 */

function mat4Identity() {
    return new Float32Array([
        1, 0, 0, 0,
        0, 1, 0, 0,
        0, 0, 1, 0,
        0, 0, 0, 1,
    ]);
}

function mat4Perspective(fovDeg, aspect, near, far) {
    const f = 1.0 / Math.tan(fovDeg * Math.PI / 360);
    const nf = 1.0 / (near - far);
    return new Float32Array([
        f / aspect, 0, 0, 0,
        0, f, 0, 0,
        0, 0, (far + near) * nf, -1,
        0, 0, 2 * far * near * nf, 0,
    ]);
}

function mat4LookAt(eye, target, up) {
    const zAxis = vecNormalize(vecSub(eye, target));
    const xAxis = vecNormalize(vecCross(up, zAxis));
    const yAxis = vecCross(zAxis, xAxis);

    return new Float32Array([
        xAxis[0], yAxis[0], zAxis[0], 0,
        xAxis[1], yAxis[1], zAxis[1], 0,
        xAxis[2], yAxis[2], zAxis[2], 0,
        -vecDot(xAxis, eye), -vecDot(yAxis, eye), -vecDot(zAxis, eye), 1,
    ]);
}

function mat4RotateY(m, angle) {
    const c = Math.cos(angle), s = Math.sin(angle);
    const r = mat4Identity();
    r[0] = c; r[2] = -s;
    r[8] = s; r[10] = c;
    return mat4Multiply(m, r);
}

function mat4RotateX(m, angle) {
    const c = Math.cos(angle), s = Math.sin(angle);
    const r = mat4Identity();
    r[5] = c; r[6] = s;
    r[9] = -s; r[10] = c;
    return mat4Multiply(m, r);
}

function mat4Multiply(a, b) {
    const out = new Float32Array(16);
    for (let i = 0; i < 4; i++) {
        for (let j = 0; j < 4; j++) {
            out[j * 4 + i] =
                a[0 * 4 + i] * b[j * 4 + 0] +
                a[1 * 4 + i] * b[j * 4 + 1] +
                a[2 * 4 + i] * b[j * 4 + 2] +
                a[3 * 4 + i] * b[j * 4 + 3];
        }
    }
    return out;
}

/* Extract the 3x3 normal matrix from a 4x4 model matrix.
 * For the common case of rotation + uniform scale, the upper-left 3x3
 * of the model matrix works.  For non-uniform scale, we'd need the
 * inverse transpose -- but this suffices for our cube demo. */
function mat3NormalFromMat4(m) {
    return new Float32Array([
        m[0], m[1], m[2],
        m[4], m[5], m[6],
        m[8], m[9], m[10],
    ]);
}

// Vector helpers
function vecSub(a, b) { return [a[0]-b[0], a[1]-b[1], a[2]-b[2]]; }
function vecCross(a, b) {
    return [
        a[1]*b[2] - a[2]*b[1],
        a[2]*b[0] - a[0]*b[2],
        a[0]*b[1] - a[1]*b[0],
    ];
}
function vecDot(a, b) { return a[0]*b[0] + a[1]*b[1] + a[2]*b[2]; }
function vecNormalize(v) {
    const len = Math.sqrt(vecDot(v, v));
    return len > 1e-10 ? [v[0]/len, v[1]/len, v[2]/len] : [0, 0, 0];
}

// =========================================================================
// 6. Camera and interaction state
// =========================================================================

let orbitX = 0.5;   // Horizontal orbit angle (radians)
let orbitY = 0.4;   // Vertical orbit angle
let distance = 5.0; // Camera distance from origin
let lightPos = [3.0, 3.0, 4.0];

let dragging = false;
let lastMX = 0, lastMY = 0;

canvas.addEventListener('mousedown', (e) => {
    dragging = true;
    lastMX = e.clientX;
    lastMY = e.clientY;
});

canvas.addEventListener('mousemove', (e) => {
    if (!dragging) return;
    const dx = e.clientX - lastMX;
    const dy = e.clientY - lastMY;
    lastMX = e.clientX;
    lastMY = e.clientY;

    /*
     * Why scale by 0.005?  This converts pixel movement to radians.
     * The exact factor is tuned for "feels right" sensitivity -- too
     * high and the camera spins wildly, too low and you need big drags.
     */
    orbitX += dx * 0.005;
    orbitY += dy * 0.005;

    // Clamp vertical orbit to prevent flipping
    orbitY = Math.max(-Math.PI / 2 + 0.01, Math.min(Math.PI / 2 - 0.01, orbitY));
});

canvas.addEventListener('mouseup', () => { dragging = false; });
canvas.addEventListener('mouseleave', () => { dragging = false; });

canvas.addEventListener('wheel', (e) => {
    e.preventDefault();
    distance += e.deltaY * 0.01;
    distance = Math.max(2, Math.min(15, distance));
});

document.addEventListener('keydown', (e) => {
    const step = 0.3;
    switch (e.key.toLowerCase()) {
        case 'w': lightPos[1] += step; break;
        case 's': lightPos[1] -= step; break;
        case 'a': lightPos[0] -= step; break;
        case 'd': lightPos[0] += step; break;
        case 'arrowup':   e.preventDefault(); distance -= 0.3; break;
        case 'arrowdown': e.preventDefault(); distance += 0.3; break;
        case 'r':
            orbitX = 0.5; orbitY = 0.4; distance = 5.0;
            lightPos = [3.0, 3.0, 4.0];
            break;
    }
    distance = Math.max(2, Math.min(15, distance));
});

// =========================================================================
// 7. Render loop
// =========================================================================

function render() {
    gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

    // Compute camera position from orbit angles
    // Why spherical coordinates?  Orbit cameras naturally map to
    // latitude/longitude, which spherical coordinates express directly.
    const eyeX = distance * Math.cos(orbitY) * Math.sin(orbitX);
    const eyeY = distance * Math.sin(orbitY);
    const eyeZ = distance * Math.cos(orbitY) * Math.cos(orbitX);
    const eye = [eyeX, eyeY, eyeZ];

    // Build matrices
    const model = mat4Identity();  // Cube at origin, no transform
    const view = mat4LookAt(eye, [0, 0, 0], [0, 1, 0]);
    const projection = mat4Perspective(50, canvas.width / canvas.height, 0.1, 100);
    const normalMatrix = mat3NormalFromMat4(model);

    // Upload uniforms
    gl.uniformMatrix4fv(loc.model, false, model);
    gl.uniformMatrix4fv(loc.view, false, view);
    gl.uniformMatrix4fv(loc.projection, false, projection);
    gl.uniformMatrix3fv(loc.normalMatrix, false, normalMatrix);
    gl.uniform3fv(loc.lightPos, lightPos);
    gl.uniform3fv(loc.viewPos, eye);

    // Draw indexed triangles
    // Why drawElements instead of drawArrays?  We're using an index
    // buffer to avoid duplicating vertex data.  drawElements looks up
    // vertex indices from the ELEMENT_ARRAY_BUFFER.
    gl.drawElements(gl.TRIANGLES, 36, gl.UNSIGNED_SHORT, 0);

    requestAnimationFrame(render);
}

requestAnimationFrame(render);

</script>
</body>
</html>
