"""
Exercise Solutions: MLflow Advanced
===========================================
Lesson 04 from MLOps topic.

Exercises
---------
1. Create MLflow Project — Define an MLproject file structure with conda
   environment, entry points, and parameters.
2. Custom pyfunc Model — Implement a custom MLflow pyfunc model that wraps
   preprocessing + inference logic.
3. Model Registry Workflow — Simulate the full model registry lifecycle:
   register, transition stages, compare versions.
"""

import json
import math
import random
from datetime import datetime, timedelta


# ============================================================
# Exercise 1: Create MLflow Project
# ============================================================

def exercise_1_mlflow_project():
    """Define an MLflow Project structure for a text classification pipeline.

    An MLflow Project packages ML code for reproducibility. It includes:
    - MLproject file: defines entry points, parameters, and environment
    - conda.yaml: specifies dependencies
    - Python scripts: the actual ML code

    We simulate generating these files and validating the project structure.
    """

    # --- MLproject file ---
    mlproject_content = """name: text-classification-pipeline

# Conda environment specification
conda_env: conda.yaml

# Entry points define how to run different parts of the pipeline.
# Each entry point has parameters with types, defaults, and descriptions.
entry_points:

  # Data preparation: download and preprocess text data
  prepare_data:
    parameters:
      data_url: {type: str, default: "s3://ml-data/text_classification/raw/"}
      output_dir: {type: str, default: "./data/processed"}
      max_samples: {type: int, default: 10000}
      test_ratio: {type: float, default: 0.2}
    command: "python prepare_data.py --data-url {data_url} --output-dir {output_dir} --max-samples {max_samples} --test-ratio {test_ratio}"

  # Model training with configurable hyperparameters
  train:
    parameters:
      data_dir: {type: str, default: "./data/processed"}
      model_type: {type: str, default: "tfidf_logreg"}
      max_features: {type: int, default: 5000}
      ngram_range: {type: str, default: "1,2"}
      regularization: {type: float, default: 1.0}
      epochs: {type: int, default: 10}
    command: "python train.py --data-dir {data_dir} --model-type {model_type} --max-features {max_features} --ngram-range {ngram_range} --regularization {regularization} --epochs {epochs}"

  # Full pipeline: prepare + train + evaluate
  main:
    parameters:
      data_url: {type: str, default: "s3://ml-data/text_classification/raw/"}
      model_type: {type: str, default: "tfidf_logreg"}
      max_features: {type: int, default: 5000}
    command: "python main.py --data-url {data_url} --model-type {model_type} --max-features {max_features}"
"""

    # --- conda.yaml ---
    conda_yaml_content = """name: text-classification
channels:
  - defaults
  - conda-forge
dependencies:
  - python=3.11
  - pip
  - pip:
    - mlflow>=2.10
    - scikit-learn>=1.4
    - pandas>=2.1
    - numpy>=1.26
    - nltk>=3.8
    - joblib>=1.3
"""

    # --- Project structure ---
    project_structure = {
        "text-classification-pipeline/": {
            "MLproject": mlproject_content,
            "conda.yaml": conda_yaml_content,
            "prepare_data.py": "# Data preparation script",
            "train.py": "# Model training script",
            "main.py": "# Full pipeline orchestrator",
            "evaluate.py": "# Model evaluation script",
            "data/": {
                "processed/": "(generated by prepare_data)",
            },
            "tests/": {
                "test_prepare.py": "# Unit tests for data preparation",
                "test_train.py": "# Unit tests for training",
            },
        }
    }

    def print_tree(structure, indent=0):
        """Pretty-print a directory tree."""
        for name, content in structure.items():
            prefix = "  " * indent
            if isinstance(content, dict):
                print(f"{prefix}{name}")
                print_tree(content, indent + 1)
            else:
                print(f"{prefix}{name}")

    print("MLflow Project Structure:")
    print("-" * 40)
    print_tree(project_structure)

    print("\n\nMLproject file:")
    print("-" * 40)
    print(mlproject_content)

    print("\nconda.yaml:")
    print("-" * 40)
    print(conda_yaml_content)

    # --- Validate project configuration ---
    print("\nProject Validation:")
    print("-" * 40)

    # Parse entry points from the MLproject content
    entry_points = ["prepare_data", "train", "main"]
    for ep in entry_points:
        has_ep = ep in mlproject_content
        status = "OK" if has_ep else "MISSING"
        print(f"  Entry point '{ep}': {status}")

    has_conda = "conda_env" in mlproject_content
    print(f"  Conda environment: {'OK' if has_conda else 'MISSING'}")

    # Example usage commands
    print("\nExample usage:")
    print("  # Run the full pipeline")
    print("  mlflow run . -e main --experiment-name text-clf")
    print()
    print("  # Run just training with custom params")
    print("  mlflow run . -e train -P model_type=tfidf_svm -P max_features=10000")
    print()
    print("  # Run from a Git repo")
    print("  mlflow run https://github.com/user/text-clf.git -e main")

    return project_structure


# ============================================================
# Exercise 2: Custom pyfunc Model
# ============================================================

def exercise_2_custom_pyfunc():
    """Implement a custom pyfunc model that wraps preprocessing + inference.

    MLflow's pyfunc interface allows wrapping arbitrary Python code as a model.
    The key methods:
    - load_context(): Load model artifacts (weights, tokenizers, etc.)
    - predict(): Run preprocessing + inference on new data

    This is useful when your model needs custom preprocessing that must
    travel with the model (e.g., text normalization, feature engineering).
    """

    class CustomTextClassifier:
        """A custom pyfunc-style model for text classification.

        This model wraps:
        1. Text preprocessing (lowercasing, stopword removal, tokenization)
        2. TF-IDF-like feature extraction (simulated with word frequency)
        3. Logistic regression prediction

        In real MLflow, this would extend mlflow.pyfunc.PythonModel.
        """

        def __init__(self):
            self.vocabulary = {}
            self.weights = []
            self.bias = 0.0
            self.stopwords = {
                "the", "a", "an", "is", "are", "was", "were", "be", "been",
                "being", "have", "has", "had", "do", "does", "did", "will",
                "would", "could", "should", "may", "might", "must", "shall",
                "can", "need", "dare", "ought", "used", "to", "of", "in",
                "for", "on", "with", "at", "by", "from", "as", "into",
                "through", "during", "before", "after", "above", "below",
                "between", "out", "off", "over", "under", "again", "further",
                "then", "once", "and", "but", "or", "nor", "not", "so", "yet",
                "both", "either", "neither", "each", "every", "all", "any",
                "few", "more", "most", "other", "some", "such", "no", "only",
                "own", "same", "than", "too", "very", "it", "its", "this",
                "that", "these", "those", "i", "me", "my", "myself", "we",
                "our", "ours", "ourselves", "you", "your", "yours", "he",
                "him", "his", "she", "her", "hers", "they", "them", "their",
            }

        def _preprocess(self, text):
            """Text preprocessing pipeline."""
            # Lowercase
            text = text.lower()
            # Remove punctuation (simple approach)
            text = "".join(c if c.isalnum() or c.isspace() else " " for c in text)
            # Tokenize
            tokens = text.split()
            # Remove stopwords
            tokens = [t for t in tokens if t not in self.stopwords and len(t) > 1]
            return tokens

        def _text_to_features(self, tokens):
            """Convert tokens to feature vector using vocabulary."""
            features = [0.0] * len(self.vocabulary)
            for token in tokens:
                if token in self.vocabulary:
                    idx = self.vocabulary[token]
                    features[idx] += 1.0
            # L2 normalize
            norm = math.sqrt(sum(f * f for f in features) + 1e-8)
            features = [f / norm for f in features]
            return features

        def fit(self, texts, labels, max_vocab=100, lr=0.1, epochs=50):
            """Train the model (build vocab + train classifier)."""
            # Build vocabulary from training data
            word_counts = {}
            for text in texts:
                tokens = self._preprocess(text)
                for token in tokens:
                    word_counts[token] = word_counts.get(token, 0) + 1

            # Keep top-N words as vocabulary
            sorted_words = sorted(word_counts.items(), key=lambda x: -x[1])
            self.vocabulary = {
                word: idx for idx, (word, _) in enumerate(sorted_words[:max_vocab])
            }

            # Convert texts to feature vectors
            X = [self._text_to_features(self._preprocess(text)) for text in texts]

            # Train logistic regression
            n_features = len(self.vocabulary)
            self.weights = [random.gauss(0, 0.01) for _ in range(n_features)]
            self.bias = 0.0

            for epoch in range(epochs):
                for features, label in zip(X, labels):
                    z = sum(w * f for w, f in zip(self.weights, features)) + self.bias
                    z = max(-500, min(500, z))
                    pred = 1 / (1 + math.exp(-z))
                    error = pred - label
                    for j in range(n_features):
                        self.weights[j] -= lr * error * features[j]
                    self.bias -= lr * error

        def load_context(self, context):
            """Load model artifacts (simulated).

            In real MLflow pyfunc, this loads from the artifact store:
            - context.artifacts["model_weights"] -> path to weights file
            - context.artifacts["vocabulary"] -> path to vocab file
            """
            # In production, this would load from disk:
            # with open(context.artifacts["vocabulary"]) as f:
            #     self.vocabulary = json.load(f)
            # with open(context.artifacts["model_weights"]) as f:
            #     data = json.load(f)
            #     self.weights = data["weights"]
            #     self.bias = data["bias"]
            print("  [load_context] Model artifacts loaded successfully")

        def predict(self, model_input):
            """Run preprocessing + inference on new data.

            In real MLflow pyfunc, model_input would be a pandas DataFrame.
            Here we accept a list of text strings.
            """
            results = []
            for text in model_input:
                tokens = self._preprocess(text)
                features = self._text_to_features(tokens)
                z = sum(w * f for w, f in zip(self.weights, features)) + self.bias
                z = max(-500, min(500, z))
                prob = 1 / (1 + math.exp(-z))
                results.append({
                    "text": text[:50] + "..." if len(text) > 50 else text,
                    "prediction": "positive" if prob >= 0.5 else "negative",
                    "confidence": round(prob if prob >= 0.5 else 1 - prob, 4),
                    "raw_probability": round(prob, 4),
                })
            return results

        def save_model(self):
            """Serialize model for MLflow artifact logging."""
            return {
                "vocabulary": self.vocabulary,
                "weights": self.weights,
                "bias": self.bias,
                "stopwords_count": len(self.stopwords),
                "vocab_size": len(self.vocabulary),
            }

    # --- Training data (simulated movie reviews) ---
    training_texts = [
        "This movie was absolutely fantastic and wonderful",
        "Terrible film with awful acting and boring plot",
        "Great performances and brilliant cinematography",
        "Waste of time, completely predictable and dull",
        "Loved every minute of this masterpiece",
        "Worst movie I have ever seen, just horrible",
        "Beautiful story with amazing character development",
        "So bad it made me want to leave the theater",
        "Incredible direction and superb screenplay",
        "Disappointing and poorly executed from start to finish",
        "Outstanding film that exceeded all expectations",
        "Boring, unoriginal, and completely forgettable",
        "A delightful and heartwarming experience",
        "Dreadful acting with a ridiculous storyline",
        "Masterfully crafted with stunning visual effects",
        "Painfully slow and utterly meaningless",
    ]
    training_labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]

    # --- Build and train the custom pyfunc model ---
    print("Building Custom pyfunc Model")
    print("-" * 40)

    model = CustomTextClassifier()
    model.fit(training_texts, training_labels, max_vocab=100, lr=0.1, epochs=50)
    print(f"  Vocabulary size: {len(model.vocabulary)}")
    print(f"  Top 10 vocab words: {list(model.vocabulary.keys())[:10]}")

    # --- Simulate MLflow model logging ---
    print("\nSimulated MLflow Model Logging:")
    print("-" * 40)
    model_artifacts = model.save_model()
    print(f"  Model saved with {model_artifacts['vocab_size']} vocab entries")
    print(f"  Weights shape: ({len(model_artifacts['weights'])},)")

    # --- Test prediction (simulates loading and serving) ---
    print("\nPrediction (via pyfunc interface):")
    print("-" * 40)
    model.load_context(None)  # Simulated artifact loading

    test_texts = [
        "This is an amazing and wonderful film",
        "Absolutely terrible, worst experience ever",
        "Decent movie with some good moments",
        "The acting was superb and the plot was engaging",
        "I fell asleep halfway through, so boring",
    ]

    predictions = model.predict(test_texts)
    for pred in predictions:
        print(f"  '{pred['text']}'")
        print(f"    -> {pred['prediction']} (confidence: {pred['confidence']:.2%})")

    return model


# ============================================================
# Exercise 3: Model Registry Workflow
# ============================================================

def exercise_3_model_registry():
    """Simulate the full MLflow Model Registry lifecycle.

    The Model Registry provides:
    - Model versioning (track multiple versions of a named model)
    - Stage transitions (None -> Staging -> Production -> Archived)
    - Approval workflows (annotations, descriptions)
    - Version comparison
    """

    class ModelVersion:
        """A single version of a registered model."""

        def __init__(self, version, run_id, metrics, description=""):
            self.version = version
            self.run_id = run_id
            self.metrics = metrics
            self.description = description
            self.stage = "None"
            self.tags = {}
            self.created_at = datetime.now()
            self.transition_history = []

        def transition_to(self, new_stage, comment=""):
            old_stage = self.stage
            self.stage = new_stage
            self.transition_history.append({
                "from": old_stage,
                "to": new_stage,
                "comment": comment,
                "timestamp": datetime.now().isoformat(),
            })

    class ModelRegistry:
        """Simulated MLflow Model Registry."""

        def __init__(self):
            self.registered_models = {}

        def create_registered_model(self, name, description=""):
            self.registered_models[name] = {
                "name": name,
                "description": description,
                "versions": [],
                "created_at": datetime.now().isoformat(),
            }
            print(f"  Created registered model: '{name}'")

        def register_version(self, model_name, run_id, metrics, description=""):
            model = self.registered_models[model_name]
            version_num = len(model["versions"]) + 1
            version = ModelVersion(version_num, run_id, metrics, description)
            model["versions"].append(version)
            print(f"  Registered version {version_num} (run: {run_id})")
            return version

        def transition_stage(self, model_name, version_num, stage, comment=""):
            model = self.registered_models[model_name]
            version = model["versions"][version_num - 1]

            # Enforce valid transitions
            valid_transitions = {
                "None": ["Staging"],
                "Staging": ["Production", "Archived", "None"],
                "Production": ["Archived", "Staging"],
                "Archived": ["None"],
            }

            if stage not in valid_transitions.get(version.stage, []):
                print(f"  ERROR: Cannot transition from '{version.stage}' to '{stage}'")
                return False

            # If moving to Production, archive any existing production version
            if stage == "Production":
                for v in model["versions"]:
                    if v.stage == "Production" and v.version != version_num:
                        v.transition_to("Archived",
                                        f"Replaced by version {version_num}")
                        print(f"  Archived version {v.version} "
                              f"(replaced by version {version_num})")

            version.transition_to(stage, comment)
            print(f"  Version {version_num}: '{version.stage}' "
                  f"(comment: {comment})")
            return True

        def get_production_version(self, model_name):
            model = self.registered_models[model_name]
            for v in model["versions"]:
                if v.stage == "Production":
                    return v
            return None

        def compare_versions(self, model_name, v1_num, v2_num):
            model = self.registered_models[model_name]
            v1 = model["versions"][v1_num - 1]
            v2 = model["versions"][v2_num - 1]

            print(f"\n  Comparing Version {v1_num} vs Version {v2_num}:")
            print(f"  {'Metric':<20s} {'V' + str(v1_num):>10s} {'V' + str(v2_num):>10s} {'Delta':>10s}")
            print(f"  {'-'*50}")
            for metric in v1.metrics:
                val1 = v1.metrics[metric]
                val2 = v2.metrics.get(metric, 0)
                delta = val2 - val1
                arrow = "+" if delta > 0 else ""
                print(f"  {metric:<20s} {val1:>10.4f} {val2:>10.4f} {arrow}{delta:>9.4f}")

    # --- Simulate the full registry workflow ---
    registry = ModelRegistry()

    print("Model Registry Workflow")
    print("=" * 60)

    # Step 1: Create a registered model
    print("\n1. Create Registered Model")
    print("-" * 40)
    registry.create_registered_model(
        "fraud-detector",
        description="XGBoost-based credit card fraud detection model",
    )

    # Step 2: Register multiple versions (simulating improving models)
    print("\n2. Register Model Versions")
    print("-" * 40)

    versions_data = [
        {
            "run_id": "run_001",
            "metrics": {"accuracy": 0.92, "precision": 0.65, "recall": 0.88, "f1": 0.75, "auc_pr": 0.78},
            "description": "Baseline logistic regression",
        },
        {
            "run_id": "run_015",
            "metrics": {"accuracy": 0.95, "precision": 0.72, "recall": 0.91, "f1": 0.80, "auc_pr": 0.85},
            "description": "Random forest with feature engineering",
        },
        {
            "run_id": "run_032",
            "metrics": {"accuracy": 0.96, "precision": 0.78, "recall": 0.93, "f1": 0.85, "auc_pr": 0.90},
            "description": "XGBoost with SMOTE oversampling",
        },
        {
            "run_id": "run_048",
            "metrics": {"accuracy": 0.97, "precision": 0.82, "recall": 0.94, "f1": 0.88, "auc_pr": 0.93},
            "description": "XGBoost with transaction velocity features",
        },
    ]

    for vd in versions_data:
        v = registry.register_version("fraud-detector", **vd)

    # Step 3: Stage transitions with approval workflow
    print("\n3. Stage Transitions")
    print("-" * 40)

    # Move v3 to staging for testing
    registry.transition_stage("fraud-detector", 3, "Staging",
                              "Promoted for A/B testing")

    # After testing, move v3 to production
    registry.transition_stage("fraud-detector", 3, "Production",
                              "Passed A/B test: +5% recall vs v2")

    # Later, v4 is ready — move to staging
    registry.transition_stage("fraud-detector", 4, "Staging",
                              "New velocity features show promise")

    # Promote v4 to production (automatically archives v3)
    registry.transition_stage("fraud-detector", 4, "Production",
                              "7% F1 improvement over v3, approved by ML lead")

    # Step 4: Compare versions
    print("\n4. Version Comparison")
    print("-" * 40)
    registry.compare_versions("fraud-detector", 3, 4)

    # Step 5: Show current state
    print("\n\n5. Current Registry State")
    print("-" * 40)
    model = registry.registered_models["fraud-detector"]
    for v in model["versions"]:
        print(f"  Version {v.version}: stage={v.stage:<12s} "
              f"run={v.run_id}  {v.description}")

    # Production version
    prod = registry.get_production_version("fraud-detector")
    if prod:
        print(f"\n  Current Production: Version {prod.version}")
        print(f"  Metrics: {json.dumps(prod.metrics, indent=4)}")
        print(f"  Transition History:")
        for t in prod.transition_history:
            print(f"    {t['from']} -> {t['to']}: {t['comment']}")

    return registry


# ============================================================
# Main
# ============================================================

if __name__ == "__main__":
    print("Exercise 1: Create MLflow Project")
    print("=" * 60)
    exercise_1_mlflow_project()

    print("\n\n")
    print("Exercise 2: Custom pyfunc Model")
    print("=" * 60)
    exercise_2_custom_pyfunc()

    print("\n\n")
    print("Exercise 3: Model Registry Workflow")
    print("=" * 60)
    exercise_3_model_registry()
