#!/bin/bash
# Exercises for Lesson 25: High Availability Cluster
# Topic: Linux
# Solutions to practice problems from the lesson.

# === Exercise 1: Cluster Configuration ===
# Problem: Set up a 2-node cluster using pcs (Pacemaker/Corosync).
exercise_1() {
    echo "=== Exercise 1: 2-Node Cluster Setup with pcs ==="
    echo ""
    echo "Scenario: Create a Pacemaker/Corosync high-availability cluster with 2 nodes."
    echo ""

    echo "Prerequisites:"
    echo "  - 2 servers (node1, node2) with RHEL/CentOS/Rocky"
    echo "  - Packages: pacemaker, corosync, pcs"
    echo "  - Hostnames resolvable (via /etc/hosts or DNS)"
    echo "  - Firewall allows corosync (UDP 5404-5405) and pcsd (TCP 2224)"
    echo ""

    echo "--- Step 1: Start pcsd and set hacluster password ---"
    echo "  # Run on BOTH nodes:"
    echo "  sudo systemctl enable pcsd"
    echo "  sudo systemctl start pcsd"
    echo "  sudo passwd hacluster     # Set the same password on both nodes"
    echo ""
    echo "  Why: pcsd is the daemon that pcs communicates with."
    echo "  'hacluster' is the system user that pcs uses for inter-node authentication."
    echo ""

    echo "--- Step 2: Authenticate nodes ---"
    echo "  # Run on ONE node:"
    echo "  sudo pcs host auth node1 node2"
    echo "  # Enter hacluster username and password when prompted"
    echo ""
    echo "  Why: Establishes trust between nodes. pcs stores auth tokens so"
    echo "  subsequent commands can manage both nodes from either one."
    echo ""

    echo "--- Step 3: Create and start the cluster ---"
    echo "  sudo pcs cluster setup mycluster node1 node2"
    echo "  sudo pcs cluster start --all      # Start cluster on all nodes"
    echo "  sudo pcs cluster enable --all     # Auto-start cluster on boot"
    echo ""
    echo "  'setup' generates corosync.conf and distributes it to all nodes."
    echo "  'start --all' activates Corosync (membership/messaging) and"
    echo "  Pacemaker (resource management) on both nodes."
    echo ""

    echo "--- Step 4: Set basic cluster properties ---"
    echo "  sudo pcs property set stonith-enabled=false   # Disable fencing (for testing ONLY)"
    echo "  sudo pcs property set no-quorum-policy=ignore # Needed for 2-node clusters"
    echo ""
    echo "  IMPORTANT:"
    echo "    STONITH (Shoot The Other Node In The Head) = fencing mechanism"
    echo "    In production, ALWAYS enable STONITH to prevent split-brain."
    echo "    Split-brain: both nodes think they're primary -> data corruption."
    echo "    Fencing kills the unresponsive node to guarantee only one is active."
    echo ""
    echo "    no-quorum-policy=ignore: In a 2-node cluster, losing one node means"
    echo "    no quorum (need >50%). 'ignore' allows the surviving node to continue."
    echo ""

    echo "--- Step 5: Verify ---"
    echo "  sudo pcs cluster status      # Overall cluster status"
    echo "  sudo pcs status              # Resources and node status"
    echo "  sudo corosync-quorumtool     # Quorum status"
    echo "  sudo pcs cluster cib         # Dump cluster configuration (XML)"
}

# === Exercise 2: Resource Group ===
# Problem: Create a resource group with VIP, filesystem, and PostgreSQL.
exercise_2() {
    echo "=== Exercise 2: Resource Group (VIP + Filesystem + PostgreSQL) ==="
    echo ""
    echo "Scenario: Create a group of dependent resources that must run together"
    echo "on the same node, starting in order."
    echo ""

    echo "--- Step 1: Create VIP resource ---"
    echo "  sudo pcs resource create VIP ocf:heartbeat:IPaddr2 \\"
    echo "      ip=192.168.1.200 cidr_netmask=24"
    echo ""
    echo "  Breakdown:"
    echo "    VIP                      = resource name"
    echo "    ocf:heartbeat:IPaddr2    = resource agent (OCF standard, heartbeat provider)"
    echo "    ip=192.168.1.200         = virtual IP address"
    echo "    cidr_netmask=24          = subnet mask (/24 = 255.255.255.0)"
    echo ""
    echo "  The VIP floats between nodes. Clients connect to this IP,"
    echo "  and it moves to the active node during failover."
    echo ""

    echo "--- Step 2: Create Filesystem resource ---"
    echo "  sudo pcs resource create DataFS ocf:heartbeat:Filesystem \\"
    echo "      device=/dev/sdb1 directory=/data fstype=ext4"
    echo ""
    echo "  Why: Shared storage (SAN/DRBD) must be mounted only on the active node."
    echo "  Pacemaker manages mount/unmount during failover."
    echo ""

    echo "--- Step 3: Create PostgreSQL resource ---"
    echo "  sudo pcs resource create PostgreSQL ocf:heartbeat:pgsql \\"
    echo "      pgctl=/usr/lib/postgresql/14/bin/pg_ctl \\"
    echo "      pgdata=/var/lib/postgresql/14/main \\"
    echo "      op start timeout=60s \\"
    echo "      op stop timeout=60s \\"
    echo "      op monitor interval=10s"
    echo ""
    echo "  'op' defines operation timeouts:"
    echo "    start timeout=60s   = allow 60s for PostgreSQL to start"
    echo "    stop timeout=60s    = allow 60s for graceful shutdown"
    echo "    monitor interval=10s = check health every 10 seconds"
    echo ""

    echo "--- Step 4: Create resource group ---"
    echo "  sudo pcs resource group add DBGroup DataFS VIP PostgreSQL"
    echo ""
    echo "  Group behavior:"
    echo "    - Resources start in order: DataFS -> VIP -> PostgreSQL"
    echo "    - Resources stop in reverse: PostgreSQL -> VIP -> DataFS"
    echo "    - All resources run on the same node"
    echo "    - If any resource fails, the entire group may migrate"
    echo ""

    echo "--- Step 5: Add explicit ordering constraint (optional, group implies it) ---"
    echo "  sudo pcs constraint order DataFS then VIP then PostgreSQL"
    echo ""
    echo "  Why explicit ordering matters:"
    echo "    1. Mount filesystem first (DataFS) -> PostgreSQL data is accessible"
    echo "    2. Assign VIP -> Clients can connect"
    echo "    3. Start PostgreSQL -> Service is ready"
    echo "    Reverse on stop: shutdown DB -> release VIP -> unmount"
    echo ""

    echo "--- Verify ---"
    echo "  sudo pcs status                       # Show all resources and groups"
    echo "  sudo pcs resource show DBGroup        # Show group details"
    echo "  sudo pcs constraint show              # Show all constraints"
    echo ""

    echo "Testing failover:"
    echo "  sudo pcs node standby node1           # Put node1 in standby"
    echo "  sudo pcs status                       # Verify group moved to node2"
    echo "  sudo pcs node unstandby node1         # Bring node1 back"
}

# === Exercise 3: DRBD Replication Status ===
# Problem: Check current status and sync state of DRBD resource r0.
exercise_3() {
    echo "=== Exercise 3: DRBD Replication Status ==="
    echo ""
    echo "Scenario: Monitor DRBD (Distributed Replicated Block Device) replication"
    echo "to ensure data is synchronized between nodes."
    echo ""

    echo "DRBD overview:"
    echo "  DRBD creates a network mirror of a block device (like RAID-1 over network)."
    echo "  Primary node: read-write access to the device"
    echo "  Secondary node: receives replication data (read-only or standby)"
    echo ""

    echo "--- Command 1: Check DRBD status ---"
    echo "  sudo drbdadm status r0"
    echo ""
    echo "  Example output:"
    echo "    r0 role:Primary"
    echo "      disk:UpToDate"
    echo "      peer role:Secondary"
    echo "        replication:Established peer-disk:UpToDate"
    echo ""
    echo "  Key states:"
    echo "    role:Primary/Secondary  = Which node owns the resource"
    echo "    disk:UpToDate           = Local disk is current (good)"
    echo "    disk:Inconsistent       = Data is being synced (or out of sync)"
    echo "    replication:Established = Connection is active and syncing"
    echo ""

    echo "--- Command 2: Check /proc/drbd (legacy but detailed) ---"
    echo "  cat /proc/drbd"
    echo ""
    echo "  Example output:"
    echo "    version: 8.4.11 (api:1/proto:86-101)"
    echo "    0: cs:Connected ro:Primary/Secondary ds:UpToDate/UpToDate C r-----"
    echo "       ns:12345 nr:0 dw:12345 dr:67890 al:10 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1"
    echo ""
    echo "  Abbreviations:"
    echo "    cs = Connection State (Connected, WFConnection, StandAlone)"
    echo "    ro = Roles (local/remote: Primary/Secondary)"
    echo "    ds = Disk States (local/remote: UpToDate/UpToDate)"
    echo "    ns = Network Send (KB), nr = Network Receive (KB)"
    echo ""

    echo "--- Command 3: Connection state ---"
    echo "  sudo drbdadm cstate r0"
    echo ""
    echo "  Values: Connected, WFConnection (waiting), StandAlone, Disconnecting"
    echo ""

    echo "--- Command 4: Disk state ---"
    echo "  sudo drbdadm dstate r0"
    echo ""
    echo "  Values: UpToDate, Inconsistent, DUnknown, Outdated, Diskless"
    echo "  Format: local/remote (e.g., UpToDate/UpToDate)"
    echo ""

    echo "--- Command 5: Role check ---"
    echo "  sudo drbdadm role r0"
    echo ""
    echo "  Output: Primary/Secondary or Secondary/Primary"
    echo ""

    echo "--- Command 6: All resources status ---"
    echo "  sudo drbdadm status all"
    echo ""
    echo "  Shows status of every DRBD resource on this node."
    echo ""

    echo "Troubleshooting sync issues:"
    echo "  # If sync is needed (after split-brain or new secondary)"
    echo "  # On the node with GOOD data:"
    echo "  sudo drbdadm primary r0 --force"
    echo ""
    echo "  # On the node that needs resync (data will be OVERWRITTEN):"
    echo "  sudo drbdadm secondary r0"
    echo "  sudo drbdadm disconnect r0"
    echo "  sudo drbdadm -- --discard-my-data connect r0"
    echo ""
    echo "  WARNING: --discard-my-data destroys data on that node."
    echo "  Only use when you're certain the OTHER node has correct data."
}

# Run all exercises
exercise_1
echo ""
exercise_2
echo ""
exercise_3
echo ""
echo "All exercises completed!"
