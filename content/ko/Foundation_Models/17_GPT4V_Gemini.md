# 17. GPT-4V, GPT-4o, Gemini & Claude 3

## í•™ìŠµ ëª©í‘œ(Learning Objectives)

ì´ ë ˆìŠ¨ì„ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. GPT-4V, GPT-4o, Gemini 1.5 Pro, Claude 3ì˜ í•µì‹¬ ê¸°ëŠ¥ê³¼ í•œê³„ë¥¼ ìƒìš© ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œìœ¼ë¡œì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
2. ê° ì‹œìŠ¤í…œì˜ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ ì´í•´, OCR, ì‹œê°ì  ì¶”ë¡ (visual reasoning) íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤
3. GPT-4o, Gemini 1.5 Pro, Claude 3 ëª¨ë¸ íŒ¨ë°€ë¦¬ ê°„ì˜ ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ì™€ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°(context window) í¬ê¸°ë¥¼ ë¹„êµí•  ìˆ˜ ìˆë‹¤
4. ë¬¸ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ê³¼ ì‹œê°ì  ì§ˆì˜ì‘ë‹µ(Visual Question Answering) ì‹œìŠ¤í…œ ë“± ì‹¤ìš©ì ì¸ ë©€í‹°ëª¨ë‹¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤
5. í”„ë¡œë•ì…˜ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ìƒìš© ë©€í‹°ëª¨ë‹¬ APIë¥¼ ì„ íƒí•  ë•Œ ë¹„ìš©, ì§€ì—° ì‹œê°„(latency), ê¸°ëŠ¥ ê°„ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ í‰ê°€í•  ìˆ˜ ìˆë‹¤

---

## ê°œìš”

GPT-4V(ision), GPT-4o, Gemini, Claude 3ëŠ” í˜„ì¬ ê°€ì¥ ê°•ë ¥í•œ ìƒìš© ë©€í‹°ëª¨ë‹¬ AIì…ë‹ˆë‹¤. ì´ ë ˆìŠ¨ì—ì„œëŠ” ì´ë“¤ì˜ ê¸°ëŠ¥, API ì‚¬ìš©ë²•, ê·¸ë¦¬ê³  ì‹¤ì „ ì‘ìš© ì‚¬ë¡€ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

> **2024ë…„ ì—…ë°ì´íŠ¸**:
> - **GPT-4o** (2024.05): GPT-4ì˜ "omni" ë²„ì „, ë„¤ì´í‹°ë¸Œ ë©€í‹°ëª¨ë‹¬
> - **Gemini 1.5 Pro**: 2M í† í° ì»¨í…ìŠ¤íŠ¸, ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ë„¤ì´í‹°ë¸Œ
> - **Claude 3 Family** (2024.03): Haiku, Sonnet, Opus ë¼ì¸ì—…
> - **Claude 3.5 Sonnet** (2024.06): ë¹„ì „ ê¸°ëŠ¥ ê°•í™”

---

## 1. GPT-4V (GPT-4 with Vision)

### 1.1 ê¸°ëŠ¥ ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPT-4V ì£¼ìš” ê¸°ëŠ¥                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ğŸ–¼ï¸ ì´ë¯¸ì§€ ì´í•´                                                  â”‚
â”‚  - ìƒì„¸ ì„¤ëª… ë° ë¶„ì„                                            â”‚
â”‚  - ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¹„êµ                                             â”‚
â”‚  - ì°¨íŠ¸/ê·¸ë˜í”„ í•´ì„                                             â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ (OCR)                                            â”‚
â”‚  - ì†ê¸€ì”¨ ì¸ì‹                                                   â”‚
â”‚  - ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸                                                â”‚
â”‚  - ë¬¸ì„œ êµ¬ì¡° ì´í•´                                               â”‚
â”‚                                                                  â”‚
â”‚  ğŸ” ì„¸ë¶€ ë¶„ì„                                                    â”‚
â”‚  - ê°ì²´ ì‹ë³„ ë° ì¹´ìš´íŒ…                                          â”‚
â”‚  - ê³µê°„ ê´€ê³„ ì´í•´                                               â”‚
â”‚  - ì†ì„± ì¶”ë¡                                                      â”‚
â”‚                                                                  â”‚
â”‚  ğŸ’¡ ì¶”ë¡  ë° ì°½ì‘                                                  â”‚
â”‚  - ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ë¡                                              â”‚
â”‚  - ì½”ë“œ ìƒì„± (UI ìŠ¤í¬ë¦°ìƒ· â†’ ì½”ë“œ)                               â”‚
â”‚  - ì°½ì˜ì  ê¸€ì“°ê¸°                                                â”‚
â”‚                                                                  â”‚
â”‚  âš ï¸ ì œí•œ ì‚¬í•­                                                    â”‚
â”‚  - ì˜ë£Œ ì§„ë‹¨ ë¶ˆê°€                                               â”‚
â”‚  - ì–¼êµ´ ì¸ì‹/ì‹ ì› í™•ì¸ ë¶ˆê°€                                     â”‚
â”‚  - ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ë¯¸ì§€ì› (ì´ë¯¸ì§€ë§Œ)                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 API ì‚¬ìš©ë²•

```python
from openai import OpenAI
import base64
from pathlib import Path

client = OpenAI()

def encode_image(image_path: str) -> str:
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode()


def gpt4v_basic(image_path: str, prompt: str) -> str:
    """ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„"""

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{encode_image(image_path)}"
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4v_multi_image(image_paths: list, prompt: str) -> str:
    """ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    content = [{"type": "text", "text": prompt}]

    for path in image_paths:
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{encode_image(path)}"}
        })

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[{"role": "user", "content": content}],
        max_tokens=2048
    )

    return response.choices[0].message.content


def gpt4v_with_detail(image_path: str, prompt: str, detail: str = "high") -> str:
    """
    ìƒì„¸ ìˆ˜ì¤€ ì§€ì •

    detail:
    - "low": ë¹ ë¥´ê³  ì €ë ´, ì €í•´ìƒë„ ë¶„ì„
    - "high": ìƒì„¸ ë¶„ì„, ë” ë§ì€ í† í° ì‚¬ìš©
    - "auto": ìë™ ì„ íƒ
    """

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{encode_image(image_path)}",
                            "detail": detail
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4v_url_image(image_url: str, prompt: str) -> str:
    """URL ì´ë¯¸ì§€ ë¶„ì„"""

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content
```

### 1.3 ì‹¤ì „ ì‘ìš©

```python
class GPT4VApplications:
    """GPT-4V ì‹¤ì „ ì‘ìš©"""

    def __init__(self):
        self.client = OpenAI()

    def analyze_ui_screenshot(self, screenshot_path: str) -> dict:
        """UI ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ë° ì½”ë“œ ìƒì„±"""

        prompt = """Analyze this UI screenshot and:
        1. List all UI components visible
        2. Describe the layout structure
        3. Generate HTML/CSS code to recreate this UI

        Format your response as JSON with keys:
        - components: list of UI elements
        - layout: description of layout
        - html_code: HTML implementation
        - css_code: CSS styles
        """

        response = self._call_api(screenshot_path, prompt)

        # JSON íŒŒì‹±
        import json
        try:
            return json.loads(response)
        except:
            return {"raw_response": response}

    def extract_data_from_chart(self, chart_path: str) -> dict:
        """ì°¨íŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""

        prompt = """Analyze this chart and extract:
        1. Chart type (bar, line, pie, etc.)
        2. Title and axis labels
        3. All data points with their values
        4. Key insights or trends

        Return as structured JSON.
        """

        return self._call_api(chart_path, prompt)

    def compare_images(self, image_paths: list) -> str:
        """ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„"""

        prompt = """Compare these images and describe:
        1. Similarities
        2. Differences
        3. Which image is better quality and why
        4. Any notable features in each
        """

        return gpt4v_multi_image(image_paths, prompt)

    def ocr_with_structure(self, document_path: str) -> dict:
        """êµ¬ì¡°í™”ëœ OCR"""

        prompt = """Extract all text from this document and preserve:
        1. Headings and hierarchy
        2. Tables (as markdown)
        3. Lists (numbered and bulleted)
        4. Key-value pairs

        Return as structured markdown.
        """

        return self._call_api(document_path, prompt)

    def generate_alt_text(self, image_path: str) -> str:
        """ì›¹ ì ‘ê·¼ì„±ì„ ìœ„í•œ ëŒ€ì²´ í…ìŠ¤íŠ¸ ìƒì„±"""

        prompt = """Generate an appropriate alt text for this image.
        The alt text should be:
        1. Concise (under 125 characters)
        2. Descriptive of the main content
        3. Useful for screen reader users

        Just return the alt text, nothing else.
        """

        return self._call_api(image_path, prompt)

    def _call_api(self, image_path: str, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{encode_image(image_path)}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=2048
        )
        return response.choices[0].message.content
```

---

## 2. GPT-4o (Omni)

### 2.1 GPT-4o ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPT-4o vs GPT-4V ë¹„êµ                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  GPT-4V (ê¸°ì¡´):                                                  â”‚
â”‚  - í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì…ë ¥                                          â”‚
â”‚  - ë³„ë„ì˜ ë¹„ì „ ì¸ì½”ë”                                            â”‚
â”‚  - ë¹„êµì  ëŠë¦° ì‘ë‹µ                                              â”‚
â”‚                                                                  â”‚
â”‚  GPT-4o (2024.05):                                               â”‚
â”‚  - í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ ë„¤ì´í‹°ë¸Œ                             â”‚
â”‚  - ë‹¨ì¼ ëª¨ë¸ì—ì„œ ëª¨ë“  ëª¨ë‹¬ë¦¬í‹° ì²˜ë¦¬                              â”‚
â”‚  - 2ë°° ë¹ ë¥¸ ì‘ë‹µ, 50% ì €ë ´í•œ ê°€ê²©                                â”‚
â”‚  - ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” ê°€ëŠ¥                                         â”‚
â”‚                                                                  â”‚
â”‚  ì£¼ìš” ê°œì„ ì :                                                    â”‚
â”‚  âœ… ì†ë„: í‰ê·  320ms ì‘ë‹µ (GPT-4V ëŒ€ë¹„ 2ë°°)                      â”‚
â”‚  âœ… ë¹„ìš©: ì…ë ¥ $5/1M, ì¶œë ¥ $15/1M                                â”‚
â”‚  âœ… ë¹„ì „: í–¥ìƒëœ OCR, ì°¨íŠ¸ í•´ì„                                  â”‚
â”‚  âœ… ì˜¤ë””ì˜¤: ì‹¤ì‹œê°„ ìŒì„± ì…ì¶œë ¥                                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 GPT-4o API ì‚¬ìš©ë²•

```python
from openai import OpenAI
import base64

client = OpenAI()

def gpt4o_vision(image_path: str, prompt: str) -> str:
    """GPT-4o ì´ë¯¸ì§€ ë¶„ì„"""

    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    response = client.chat.completions.create(
        model="gpt-4o",  # GPT-4o ì‚¬ìš©
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4o_audio(audio_path: str, prompt: str) -> str:
    """GPT-4o ì˜¤ë””ì˜¤ ë¶„ì„ (Realtime API)"""

    # ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
    with open(audio_path, "rb") as f:
        audio_data = base64.b64encode(f.read()).decode()

    response = client.chat.completions.create(
        model="gpt-4o-audio-preview",
        modalities=["text"],
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "input_audio",
                        "input_audio": {
                            "data": audio_data,
                            "format": "wav"
                        }
                    }
                ]
            }
        ]
    )

    return response.choices[0].message.content


# GPT-4o-mini: ì €ë¹„ìš© ë²„ì „
def gpt4o_mini_vision(image_path: str, prompt: str) -> str:
    """GPT-4o-mini: ë¹ ë¥´ê³  ì €ë ´í•œ ë¹„ì „ ëª¨ë¸"""

    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    response = client.chat.completions.create(
        model="gpt-4o-mini",  # ì €ë¹„ìš© ë²„ì „
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
                    }
                ]
            }
        ],
        max_tokens=512
    )

    return response.choices[0].message.content
```

---

## 3. Google Gemini

### 2.1 Gemini ëª¨ë¸ ë¼ì¸ì—…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gemini ëª¨ë¸ ë¹„êµ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Gemini 1.5 Flash:                                              â”‚
â”‚  - ë¹ ë¥¸ ì‘ë‹µ, ì €ë¹„ìš©                                            â”‚
â”‚  - 1M í† í° ì»¨í…ìŠ¤íŠ¸                                             â”‚
â”‚  - ì‹¤ì‹œê°„ ì‘ìš©ì— ì í•©                                           â”‚
â”‚                                                                  â”‚
â”‚  Gemini 1.5 Pro:                                                â”‚
â”‚  - ìµœê³  ì„±ëŠ¥                                                    â”‚
â”‚  - 2M í† í° ì»¨í…ìŠ¤íŠ¸                                             â”‚
â”‚  - ë³µì¡í•œ ì¶”ë¡ , ì½”ë“œ ìƒì„±                                       â”‚
â”‚                                                                  â”‚
â”‚  Gemini 1.0 Ultra:                                              â”‚
â”‚  - ê°€ì¥ í° ëª¨ë¸                                                 â”‚
â”‚  - ë³µì¡í•œ ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬                                       â”‚
â”‚                                                                  â”‚
â”‚  íŠ¹ë³„ ê¸°ëŠ¥:                                                      â”‚
â”‚  - ë„¤ì´í‹°ë¸Œ ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤)           â”‚
â”‚  - ì´ˆì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ (1ì‹œê°„ ë¹„ë””ì˜¤ ë¶„ì„ ê°€ëŠ¥)                     â”‚
â”‚  - Code execution ë‚´ì¥                                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Gemini API ì‚¬ìš©ë²•

```python
import google.generativeai as genai
from PIL import Image

# API í‚¤ ì„¤ì •
genai.configure(api_key="YOUR_API_KEY")

def gemini_basic(image_path: str, prompt: str) -> str:
    """ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    image = Image.open(image_path)

    response = model.generate_content([prompt, image])

    return response.text


def gemini_multi_image(image_paths: list, prompt: str) -> str:
    """ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    content = [prompt]
    for path in image_paths:
        content.append(Image.open(path))

    response = model.generate_content(content)

    return response.text


def gemini_video_analysis(video_path: str, prompt: str) -> str:
    """ë¹„ë””ì˜¤ ë¶„ì„ (Gemini íŠ¹í™” ê¸°ëŠ¥)"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    # ë¹„ë””ì˜¤ ì—…ë¡œë“œ
    video_file = genai.upload_file(video_path)

    # ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
    import time
    while video_file.state.name == "PROCESSING":
        time.sleep(10)
        video_file = genai.get_file(video_file.name)

    if video_file.state.name == "FAILED":
        raise ValueError("Video processing failed")

    response = model.generate_content([prompt, video_file])

    return response.text


def gemini_long_context(documents: list, query: str) -> str:
    """ê¸´ ë¬¸ì„œ ë¶„ì„ (1M+ í† í°)"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    # ëª¨ë“  ë¬¸ì„œ ê²°í•©
    content = [query]
    for doc in documents:
        if doc.endswith('.pdf'):
            content.append(genai.upload_file(doc))
        elif doc.endswith(('.jpg', '.png')):
            content.append(Image.open(doc))
        else:
            with open(doc, 'r') as f:
                content.append(f.read())

    response = model.generate_content(content)

    return response.text


def gemini_with_code_execution(prompt: str) -> dict:
    """ì½”ë“œ ì‹¤í–‰ ê¸°ëŠ¥"""

    model = genai.GenerativeModel(
        'gemini-1.5-pro',
        tools='code_execution'
    )

    response = model.generate_content(prompt)

    # ì‹¤í–‰ëœ ì½”ë“œì™€ ê²°ê³¼ ì¶”ì¶œ
    result = {
        'text': response.text,
        'code_execution': []
    }

    for part in response.parts:
        if hasattr(part, 'code_execution_result'):
            result['code_execution'].append({
                'code': part.text,
                'output': part.code_execution_result.output
            })

    return result
```

### 2.3 Gemini íŠ¹í™” ì‘ìš©

```python
class GeminiApplications:
    """Gemini íŠ¹í™” ì‘ìš©"""

    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-pro')

    def analyze_long_video(
        self,
        video_path: str,
        questions: list
    ) -> dict:
        """ê¸´ ë¹„ë””ì˜¤ ë¶„ì„ (1ì‹œê°„+)"""

        video_file = self._upload_and_wait(video_path)

        results = {}

        for question in questions:
            prompt = f"""Analyze this video and answer: {question}

            Provide timestamps when relevant.
            """

            response = self.model.generate_content([prompt, video_file])
            results[question] = response.text

        return results

    def multimodal_reasoning(
        self,
        images: list,
        audio_path: str = None,
        text: str = None
    ) -> str:
        """ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ """

        content = []

        if text:
            content.append(text)

        for img_path in images:
            content.append(Image.open(img_path))

        if audio_path:
            audio_file = self._upload_and_wait(audio_path)
            content.append(audio_file)

        response = self.model.generate_content(content)

        return response.text

    def research_assistant(
        self,
        pdf_paths: list,
        research_question: str
    ) -> dict:
        """ì—°êµ¬ ë³´ì¡° (ê¸´ ë¬¸ì„œ ë¶„ì„)"""

        # PDF ì—…ë¡œë“œ
        files = [self._upload_and_wait(path) for path in pdf_paths]

        prompt = f"""You are a research assistant. Analyze these academic papers
        and answer the following research question:

        {research_question}

        Structure your response as:
        1. Summary of relevant findings from each paper
        2. Synthesis of the findings
        3. Gaps or contradictions
        4. Suggested future directions
        """

        content = [prompt] + files

        response = self.model.generate_content(content)

        return {
            'answer': response.text,
            'sources': pdf_paths
        }

    def _upload_and_wait(self, file_path: str):
        """íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ëŒ€ê¸°"""
        import time

        file = genai.upload_file(file_path)

        while file.state.name == "PROCESSING":
            time.sleep(5)
            file = genai.get_file(file.name)

        return file
```

---

## 4. Anthropic Claude 3

### 4.1 Claude 3 ëª¨ë¸ ë¼ì¸ì—…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Claude 3 Family (2024.03)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Claude 3 Haiku:                                                 â”‚
â”‚  - ê°€ì¥ ë¹ ë¥´ê³  ì €ë ´                                              â”‚
â”‚  - ì‹¤ì‹œê°„ ì‘ìš©, ëŒ€ëŸ‰ ì²˜ë¦¬                                        â”‚
â”‚  - ë¹„ì „ ì§€ì›                                                     â”‚
â”‚                                                                  â”‚
â”‚  Claude 3 Sonnet:                                                â”‚
â”‚  - ì†ë„ì™€ ì„±ëŠ¥ì˜ ê· í˜•                                            â”‚
â”‚  - ëŒ€ë¶€ë¶„ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ë„ì— ì í•©                                 â”‚
â”‚  - ë¹„ì „ ì§€ì›                                                     â”‚
â”‚                                                                  â”‚
â”‚  Claude 3 Opus:                                                  â”‚
â”‚  - ìµœê³  ì„±ëŠ¥                                                     â”‚
â”‚  - ë³µì¡í•œ ì¶”ë¡ , ë¶„ì„ íƒœìŠ¤í¬                                      â”‚
â”‚  - ë¹„ì „ ì§€ì›                                                     â”‚
â”‚                                                                  â”‚
â”‚  Claude 3.5 Sonnet (2024.06):                                    â”‚
â”‚  - Opus ìˆ˜ì¤€ ì„±ëŠ¥, Sonnet ê°€ê²©                                   â”‚
â”‚  - í–¥ìƒëœ ë¹„ì „, ì½”ë”© ëŠ¥ë ¥                                        â”‚
â”‚  - 200K í† í° ì»¨í…ìŠ¤íŠ¸                                            â”‚
â”‚                                                                  â”‚
â”‚  íŠ¹ì§•:                                                            â”‚
â”‚  âœ… 200K ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ì „ ëª¨ë¸)                                â”‚
â”‚  âœ… ë©€í‹°ëª¨ë‹¬: ì´ë¯¸ì§€ ì´í•´                                         â”‚
â”‚  âœ… ì•ˆì „ì„±: Constitutional AI ì ìš©                                â”‚
â”‚  âœ… ë„êµ¬ ì‚¬ìš©: Function Calling ì§€ì›                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Claude API ì‚¬ìš©ë²•

```python
import anthropic
import base64

client = anthropic.Anthropic()


def claude_vision(image_path: str, prompt: str, model: str = "claude-sonnet-4-20250514") -> str:
    """Claude ë¹„ì „ ë¶„ì„"""

    # ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(image_path, "rb") as f:
        image_data = base64.standard_b64encode(f.read()).decode("utf-8")

    # ë¯¸ë””ì–´ íƒ€ì… ê²°ì •
    if image_path.endswith(".png"):
        media_type = "image/png"
    elif image_path.endswith(".gif"):
        media_type = "image/gif"
    elif image_path.endswith(".webp"):
        media_type = "image/webp"
    else:
        media_type = "image/jpeg"

    message = client.messages.create(
        model=model,
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": media_type,
                            "data": image_data,
                        },
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ],
            }
        ],
    )

    return message.content[0].text


def claude_multi_image(image_paths: list, prompt: str) -> str:
    """Claude ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    content = []

    for path in image_paths:
        with open(path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")

        media_type = "image/png" if path.endswith(".png") else "image/jpeg"

        content.append({
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": media_type,
                "data": image_data,
            }
        })

    content.append({"type": "text", "text": prompt})

    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2048,
        messages=[{"role": "user", "content": content}],
    )

    return message.content[0].text


def claude_with_tools(prompt: str, image_path: str = None) -> dict:
    """Claude Tool Use (Function Calling)"""

    tools = [
        {
            "name": "get_weather",
            "description": "Get current weather for a location",
            "input_schema": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "City name"
                    }
                },
                "required": ["location"]
            }
        }
    ]

    content = [{"type": "text", "text": prompt}]

    if image_path:
        with open(image_path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")
        content.insert(0, {
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": "image/jpeg",
                "data": image_data,
            }
        })

    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=1024,
        tools=tools,
        messages=[{"role": "user", "content": content}],
    )

    return {
        "content": message.content,
        "stop_reason": message.stop_reason
    }
```

### 4.3 Claude íŠ¹í™” ê¸°ëŠ¥

```python
class ClaudeApplications:
    """Claude íŠ¹í™” ì‘ìš©"""

    def __init__(self):
        self.client = anthropic.Anthropic()

    def long_document_analysis(self, document_text: str, query: str) -> str:
        """ê¸´ ë¬¸ì„œ ë¶„ì„ (200K í† í°)"""

        message = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            messages=[
                {
                    "role": "user",
                    "content": f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ë¬¸ì„œ:
{document_text}

ì§ˆë¬¸: {query}
"""
                }
            ],
        )

        return message.content[0].text

    def code_review(self, code: str, language: str = "python") -> str:
        """ì½”ë“œ ë¦¬ë·°"""

        message = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2048,
            messages=[
                {
                    "role": "user",
                    "content": f"""ë‹¤ìŒ {language} ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”.

```{language}
{code}
```

ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì ì¬ì  ë²„ê·¸
2. ì„±ëŠ¥ ê°œì„  ì‚¬í•­
3. ì½”ë“œ ìŠ¤íƒ€ì¼ ì œì•ˆ
4. ë³´ì•ˆ ë¬¸ì œ
"""
                }
            ],
        )

        return message.content[0].text

    def structured_output(self, image_path: str, schema: dict) -> dict:
        """êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±"""
        import json

        with open(image_path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")

        message = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2048,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": image_data,
                            }
                        },
                        {
                            "type": "text",
                            "text": f"""ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”:

{json.dumps(schema, indent=2, ensure_ascii=False)}

JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."""
                        }
                    ]
                }
            ],
        )

        return json.loads(message.content[0].text)
```

---

## 5. ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### 5.1 ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    2024 ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¹„êµ                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ê¸°ëŠ¥            GPT-4o      Gemini 1.5 Pro   Claude 3.5 Sonnet            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ì´ë¯¸ì§€ ì´í•´     â˜…â˜…â˜…â˜…â˜…     â˜…â˜…â˜…â˜…â˜…         â˜…â˜…â˜…â˜…â˜…                    â”‚
â”‚  ë¹„ë””ì˜¤ ë¶„ì„     âœ—           â˜…â˜…â˜…â˜…â˜… (ë„¤ì´í‹°ë¸Œ) âœ—                          â”‚
â”‚  ì˜¤ë””ì˜¤ ë¶„ì„     â˜…â˜…â˜…â˜…â˜†     â˜…â˜…â˜…â˜…â˜†         âœ—                          â”‚
â”‚  ì»¨í…ìŠ¤íŠ¸        128K        2M               200K                         â”‚
â”‚  ì½”ë“œ ì‹¤í–‰       âœ—           â˜…â˜…â˜…â˜…â˜† (ë‚´ì¥)  âœ—                          â”‚
â”‚  ì†ë„            â˜…â˜…â˜…â˜…â˜…     â˜…â˜…â˜…â˜…â˜† (Flash) â˜…â˜…â˜…â˜…â˜†                    â”‚
â”‚  ê°€ê²©            ì¤‘ê°„        ë‚®ìŒ             ì¤‘ê°„                         â”‚
â”‚  ì½”ë”© ëŠ¥ë ¥       â˜…â˜…â˜…â˜…â˜†     â˜…â˜…â˜…â˜…â˜†         â˜…â˜…â˜…â˜…â˜…                    â”‚
â”‚  ì¶”ë¡  ëŠ¥ë ¥       â˜…â˜…â˜…â˜…â˜…     â˜…â˜…â˜…â˜…â˜†         â˜…â˜…â˜…â˜…â˜…                    â”‚
â”‚                                                                             â”‚
â”‚  ì¶”ì²œ ì‚¬ìš© ì‚¬ë¡€:                                                            â”‚
â”‚  - GPT-4o: ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬, ìŒì„± ëŒ€í™”, ë¹ ë¥¸ ì‘ë‹µ í•„ìš” ì‹œ                    â”‚
â”‚  - Gemini: ë¹„ë””ì˜¤ ë¶„ì„, ì´ˆì¥ë¬¸ ë¬¸ì„œ, ë©€í‹°ëª¨ë‹¬ ë³µí•© íƒœìŠ¤í¬                   â”‚
â”‚  - Claude: ë³µì¡í•œ ì¶”ë¡ , ì½”ë“œ ë¦¬ë·°, ê¸´ ë¬¸ì„œ ë¶„ì„, ì•ˆì „ì„± ì¤‘ìš” ì‹œ             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 ì‚¬ìš© ì‚¬ë¡€ë³„ ì„ íƒ

```python
def select_model(use_case: str) -> str:
    """ì‚¬ìš© ì‚¬ë¡€ë³„ ëª¨ë¸ ì„ íƒ (2024 ì—…ë°ì´íŠ¸)"""

    recommendations = {
        # GPT-4oê°€ ì¢‹ì€ ê²½ìš°
        "ui_to_code": "gpt-4o",
        "realtime_chat": "gpt-4o",
        "voice_assistant": "gpt-4o-audio-preview",
        "quick_vision": "gpt-4o",

        # Geminiê°€ ì¢‹ì€ ê²½ìš°
        "video_analysis": "gemini-1.5-pro",
        "very_long_document": "gemini-1.5-pro",  # 2M ì»¨í…ìŠ¤íŠ¸
        "audio_transcription": "gemini-1.5-pro",
        "multimodal_app": "gemini-1.5-pro",

        # Claudeê°€ ì¢‹ì€ ê²½ìš°
        "complex_reasoning": "claude-sonnet-4-20250514",
        "code_review": "claude-sonnet-4-20250514",
        "long_document": "claude-sonnet-4-20250514",  # 200K ì»¨í…ìŠ¤íŠ¸
        "safety_critical": "claude-sonnet-4-20250514",

        # ë¹„ìš© ìµœì í™”
        "high_volume": "gemini-1.5-flash",
        "quick_caption": "gpt-4o-mini",
        "simple_classification": "claude-3-haiku-20240307",
    }

    return recommendations.get(use_case, "gpt-4o")
```

---

## 6. ë¹„ìš© ìµœì í™”

### 6.1 ë¹„ìš© ê³„ì‚°

```python
class CostEstimator:
    """API ë¹„ìš© ì¶”ì •"""

    # 2024ë…„ ê¸°ì¤€ ê°€ê²© (USD per 1M tokens)
    PRICING = {
        "gpt-4-vision-preview": {
            "input": 10.0,   # per 1M tokens
            "output": 30.0,  # per 1M tokens
            "image_low": 85,   # tokens
            "image_high": 765, # tokens (base) + tiles
        },
        "gpt-4o": {
            "input": 5.0,    # per 1M tokens
            "output": 15.0,  # per 1M tokens
            "image_low": 85,
            "image_high": 765,
        },
        "gpt-4o-mini": {
            "input": 0.15,   # per 1M tokens
            "output": 0.60,  # per 1M tokens
            "image_low": 85,
            "image_high": 765,
        },
        "gemini-1.5-pro": {
            "input": 1.25,   # per 1M tokens
            "output": 5.0,
            "image": 258,  # tokens per image
            "video": 263,  # tokens per second
            "audio": 32,   # tokens per second
        },
        "gemini-1.5-flash": {
            "input": 0.075,
            "output": 0.30,
        },
        "claude-3-opus": {
            "input": 15.0,   # per 1M tokens
            "output": 75.0,
        },
        "claude-sonnet-4-20250514": {
            "input": 3.0,    # per 1M tokens
            "output": 15.0,
        },
        "claude-3-haiku": {
            "input": 0.25,   # per 1M tokens
            "output": 1.25,
        },
    }

    def estimate_gpt4v_cost(
        self,
        num_images: int,
        avg_prompt_tokens: int,
        avg_response_tokens: int,
        detail: str = "high"
    ) -> float:
        """GPT-4V ë¹„ìš© ì¶”ì •"""

        pricing = self.PRICING["gpt-4-vision-preview"]

        # ì´ë¯¸ì§€ í† í°
        if detail == "low":
            image_tokens = num_images * pricing["image_low"]
        else:
            image_tokens = num_images * pricing["image_high"]

        total_input = avg_prompt_tokens + image_tokens
        total_output = avg_response_tokens

        cost = (total_input / 1000 * pricing["input"] +
                total_output / 1000 * pricing["output"])

        return cost

    def estimate_gemini_cost(
        self,
        num_images: int = 0,
        video_seconds: int = 0,
        audio_seconds: int = 0,
        text_chars: int = 0,
        output_chars: int = 0,
        model: str = "gemini-1.5-pro"
    ) -> float:
        """Gemini ë¹„ìš© ì¶”ì •"""

        pricing = self.PRICING[model]

        input_cost = text_chars / 1000 * pricing["input"]
        output_cost = output_chars / 1000 * pricing["output"]

        if model == "gemini-1.5-pro":
            # ë©€í‹°ë¯¸ë””ì–´ ë¹„ìš©
            image_tokens = num_images * pricing["image"]
            video_tokens = video_seconds * pricing["video"]
            audio_tokens = audio_seconds * pricing["audio"]

            media_chars = (image_tokens + video_tokens + audio_tokens) * 4  # í† í° â†’ ë¬¸ì ê·¼ì‚¬
            input_cost += media_chars / 1000 * pricing["input"]

        return input_cost + output_cost


# ì‚¬ìš© ì˜ˆì‹œ
estimator = CostEstimator()

# 100ê°œ ì´ë¯¸ì§€ ë¶„ì„ ë¹„ìš© ë¹„êµ
gpt4v_cost = estimator.estimate_gpt4v_cost(
    num_images=100,
    avg_prompt_tokens=100,
    avg_response_tokens=500,
    detail="high"
)

gemini_cost = estimator.estimate_gemini_cost(
    num_images=100,
    text_chars=500,
    output_chars=2000,
    model="gemini-1.5-pro"
)

print(f"GPT-4V cost: ${gpt4v_cost:.2f}")
print(f"Gemini Pro cost: ${gemini_cost:.2f}")
```

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [OpenAI GPT-4o Documentation](https://platform.openai.com/docs/guides/vision)
- [Google Gemini API](https://ai.google.dev/docs)
- [Anthropic Claude Documentation](https://docs.anthropic.com/)

### ë²¤ì¹˜ë§ˆí¬
- [MMMU Benchmark](https://mmmu-benchmark.github.io/)
- [VQA Challenge](https://visualqa.org/)
- [LMSYS Chatbot Arena](https://chat.lmsys.org/)

### ê´€ë ¨ ë ˆìŠ¨
- [16_Vision_Language_Advanced.md](16_Vision_Language_Advanced.md)
- [24_API_Evaluation.md](24_API_Evaluation.md)

---

## ì—°ìŠµ ë¬¸ì œ

### ì—°ìŠµ ë¬¸ì œ 1: í”„ë¡œë•ì…˜ ì‚¬ìš© ì‚¬ë¡€ë³„ ëª¨ë¸ ì„ íƒ
ë ˆìŠ¨ì˜ ë¹„êµ í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ í”„ë¡œë•ì…˜ ì‚¬ìš© ì‚¬ë¡€ì— ê°€ì¥ ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”. íŠ¹ì • ê¸°ëŠ¥ ë˜ëŠ” ë¹„ìš© ê³ ë ¤ì‚¬í•­ì„ ì°¸ì¡°í•˜ì—¬ ì„ íƒì„ ì •ë‹¹í™”í•˜ì„¸ìš”.

| ì‚¬ìš© ì‚¬ë¡€ | ì„ íƒëœ ëª¨ë¸ | í•µì‹¬ ì •ë‹¹í™” |
|----------|------------|------------|
| A) ì†ìœ¼ë¡œ ì“´ ì˜ë£Œ ê¸°ë¡ ì „ì‚¬ (í•˜ë£¨ 1ë§Œ í˜ì´ì§€, ë¹„ìš© ë¯¼ê°) | ??? | ??? |
| B) 2ì‹œê°„ ë³´ì•ˆ ì¹´ë©”ë¼ ì˜ìƒì—ì„œ ì´ìƒ íƒì§€ | ??? | ??? |
| C) ê³ ê° ì§€ì›ì„ ìœ„í•œ ì‹¤ì‹œê°„ ìŒì„± ë„ìš°ë¯¸ | ??? | ??? |
| D) ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì¶”ë¡ ì„ í¬í•¨í•œ ë²•ì  ê³„ì•½ ê²€í†  | ??? | ??? |
| E) ì „ììƒê±°ë˜ ì¹´íƒˆë¡œê·¸ ì œí’ˆ ì„¤ëª… ìƒì„± (í•˜ë£¨ 10ë§Œ ê°œ ì´ë¯¸ì§€) | ??? | ??? |

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

| ì‚¬ìš© ì‚¬ë¡€ | ì„ íƒëœ ëª¨ë¸ | í•µì‹¬ ì •ë‹¹í™” |
|----------|------------|------------|
| A) ì†ìœ¼ë¡œ ì“´ ì˜ë£Œ ê¸°ë¡ ì „ì‚¬ | `gpt-4o-mini` ë˜ëŠ” `claude-3-haiku` | ë†’ì€ ë³¼ë¥¨ + ë¹„ìš© ë¯¼ê° â†’ ê°€ì¥ ì €ë ´í•˜ê³  ìœ ëŠ¥í•œ ëª¨ë¸. ë‘ ëª¨ë¸ ëª¨ë‘ ê°•ë ¥í•œ OCR ì„±ëŠ¥. GPT-4o-miniëŠ” $0.15/1M í† í°ìœ¼ë¡œ, í˜ì´ì§€ë‹¹ ì•½ 1K í† í°ì˜ 1ë§Œ í˜ì´ì§€ = í•˜ë£¨ $1.50. ì˜ë£Œ ë§¥ë½ì€ ë†’ì€ ì •í™•ë„ í•„ìš”, ë°°í¬ ì „ ìƒ˜í”Œë§ìœ¼ë¡œ ê²€ì¦ í•„ìš”. |
| B) 2ì‹œê°„ ë³´ì•ˆ ì˜ìƒ ë¶„ì„ | `gemini-1.5-pro` | ë„¤ì´í‹°ë¸Œ ë¹„ë””ì˜¤ ì§€ì›ê³¼ ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸(2M í† í°)ë¥¼ ê°€ì§„ **ìœ ì¼í•œ ì˜µì…˜**. 2ì‹œê°„ Ã— 263 í† í°/ì´ˆ â‰ˆ 190ë§Œ í† í° â€” Gemini 1.5 Proì˜ 2M ì»¨í…ìŠ¤íŠ¸ ë‚´ì— ë§ìŒ. GPT-4oì™€ Claude ëª¨ë‘ ë¹„ë””ì˜¤ ì…ë ¥ì„ ë„¤ì´í‹°ë¸Œë¡œ ì§€ì›í•˜ì§€ ì•ŠìŒ. |
| C) ì‹¤ì‹œê°„ ìŒì„± ë„ìš°ë¯¸ | `gpt-4o-audio-preview` | ë„¤ì´í‹°ë¸Œ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì…ì¶œë ¥ê³¼ í‰ê·  320ms ì‘ë‹µ ì‹œê°„ì„ ê°€ì§„ **ìœ ì¼í•œ ì˜µì…˜**. "omni" ëª¨ë¸ì€ ë³„ë„ì˜ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ë‹¨ê³„ ì—†ì´ ìŒì„±ì„ ë„¤ì´í‹°ë¸Œë¡œ ì²˜ë¦¬. |
| D) ë²•ì  ê³„ì•½ ê²€í†  + ë³µì¡í•œ ì¶”ë¡  | `claude-sonnet-4-20250514` ë˜ëŠ” `claude-3-opus` | Claudeê°€ ì¶”ë¡ ê³¼ ì½”ë”©ì—ì„œ ìµœê³  ìˆœìœ„; Constitutional AI í›ˆë ¨ì´ ê³ ìœ„í—˜ ê²°ì •ì— ë” ì˜ ë³´ì •ë¨. 200K ì»¨í…ìŠ¤íŠ¸ë¡œ ê¸´ ê³„ì•½ì„œ ì²˜ë¦¬ ê°€ëŠ¥. ì•ˆì „ ì¤‘ìš” â†’ Claudeì˜ ì‹ ì¤‘í•˜ê³  ë¯¸ë¬˜í•œ ì‘ë‹µì´ í™˜ê°(hallucination) ìœ„í—˜ ê°ì†Œ. |
| E) ì „ììƒê±°ë˜ ì„¤ëª… (í•˜ë£¨ 10ë§Œ ì´ë¯¸ì§€) | `gemini-1.5-flash` ë˜ëŠ” `gpt-4o-mini` | ê°€ì¥ ë†’ì€ ë³¼ë¥¨ â†’ ê°€ì¥ ì €ë ´í•œ ëª¨ë¸. Gemini 1.5 Flash($0.075/1M ì…ë ¥ í† í°)ê°€ ê°€ì¥ ì €ë ´. ë‹¨ìˆœ ì„¤ëª… íƒœìŠ¤í¬ëŠ” ìµœëŒ€ ì„±ëŠ¥ì´ í•„ìš” ì—†ìŒ â€” ì†Œê·œëª¨ë¡œ ë¨¼ì € í’ˆì§ˆ í…ŒìŠ¤íŠ¸. |

</details>

### ì—°ìŠµ ë¬¸ì œ 2: GPT-4V ì´ë¯¸ì§€ í† í° ë¹„ìš© ê³„ì‚°
GPT-4VëŠ” `detail` íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²­êµ¬ë©ë‹ˆë‹¤. ë‹¤ìŒ ë°°ì¹˜ ì‘ì—…ì˜ ì´ API ë¹„ìš©ì„ ê³„ì‚°í•˜ì„¸ìš”:

- íƒœìŠ¤í¬: `detail="high"`ë¡œ 500ê°œ ì œí’ˆ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
- ì´ë¯¸ì§€ë‹¹ í‰ê·  í”„ë¡¬í”„íŠ¸ ê¸¸ì´: 200 í† í°
- ì´ë¯¸ì§€ë‹¹ í‰ê·  ì‘ë‹µ ê¸¸ì´: 800 í† í°
- GPT-4o ê°€ê²©: ì…ë ¥ $5.00/1M í† í°, ì¶œë ¥ $15.00/1M í† í°
- ê³ í•´ìƒë„ ì´ë¯¸ì§€: ê¸°ë³¸ 765 í† í° + íƒ€ì¼ë‹¹ 170 í† í° (ê° ì´ë¯¸ì§€ëŠ” 1024Ã—1024 â†’ 4ê°œ íƒ€ì¼ ìƒì„±)

```python
# ê³„ì‚°:
# 1. 500ê°œ ì´ë¯¸ì§€ì˜ ì´ ì´ë¯¸ì§€ í† í°
# 2. ì´ í”„ë¡¬í”„íŠ¸ í† í° (í…ìŠ¤íŠ¸ë§Œ)
# 3. ì´ ì¶œë ¥ í† í°
# 4. USD ì´ ë¹„ìš©
```

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

```python
# ì„¤ì •
num_images = 500
prompt_tokens_per_image = 200  # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ í† í°
response_tokens_per_image = 800
gpt4o_input_price = 5.00 / 1_000_000   # í† í°ë‹¹
gpt4o_output_price = 15.00 / 1_000_000  # í† í°ë‹¹

# ê³ í•´ìƒë„ ì´ë¯¸ì§€ í† í° ê³„ì‚°
# ê³ í•´ìƒë„ 1024Ã—1024:
#   ê¸°ë³¸ í† í°: 765
#   íƒ€ì¼: 1024/512 = 2 Ã— 2 = 4íƒ€ì¼, ê° 512Ã—512
#   íƒ€ì¼ í† í°: 4íƒ€ì¼ Ã— 170 í† í°/íƒ€ì¼ = 680
#   ì´ë¯¸ì§€ë‹¹ ì´ê³„: 765 + 680 = 1445 í† í°
image_tokens_per_image = 765 + (4 * 170)  # = 1445
total_image_tokens = 500 * 1445  # = 722,500 í† í°

# í…ìŠ¤íŠ¸ í† í°
total_prompt_tokens = 500 * 200  # = 100,000 í† í°
total_output_tokens = 500 * 800  # = 400,000 í† í°

# ì´ ì…ë ¥ í† í° = ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
total_input_tokens = total_image_tokens + total_prompt_tokens
                   = 722,500 + 100,000 = 822,500 í† í°

# ë¹„ìš© ê³„ì‚°
input_cost = 822,500 * (5.00 / 1_000_000) = $4.11
output_cost = 400,000 * (15.00 / 1_000_000) = $6.00

total_cost = $4.11 + $6.00 = 500ê°œ ì´ë¯¸ì§€ì— $10.11

# ì´ë¯¸ì§€ë‹¹ ë¹„ìš© ë¶„ì„:
cost_per_image = $10.11 / 500 = $0.020 per image

# ë¹„êµ: detail="low" ì‚¬ìš© ì‹œ
# ì €í•´ìƒë„: ì´ë¯¸ì§€ë‹¹ 85 í† í°
low_detail_image_tokens = 500 * 85 = 42,500 í† í°
low_detail_input_cost = (42,500 + 100,000) * (5.00 / 1_000_000) = $0.71
low_detail_output_cost = $6.00  # ë™ì¼ ì¶œë ¥
low_detail_total = $6.71  # 34% ì €ë ´í•˜ì§€ë§Œ í’ˆì§ˆ ë‚®ìŒ
```

í•µì‹¬ í†µì°°: ì´ ë°°ì¹˜ ì‘ì—…ì—ì„œ ì¶œë ¥ í† í°ì´ ë¹„ìš©ì„ ì§€ë°°í•©ë‹ˆë‹¤($10.11 ì¤‘ $6.00 = 59%). ê³ í•´ìƒë„ì—ì„œ ì €í•´ìƒë„ë¡œ ì „í™˜í•˜ëŠ” ê²ƒë³´ë‹¤ ì‘ë‹µ ê¸¸ì´ë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ë¹„ìš© ìµœì í™”ì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.

</details>

### ì—°ìŠµ ë¬¸ì œ 3: êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
ì œí’ˆ ì´ë¯¸ì§€ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ê°•ê±´í•œ Claude API í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•˜ì„¸ìš”. ì¶œë ¥ì€ íŠ¹ì • ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•˜ëŠ” ìœ íš¨í•œ JSONì´ì–´ì•¼ í•˜ë©°, í”„ë¡¬í”„íŠ¸ëŠ” ì—£ì§€ ì¼€ì´ìŠ¤(edge case)ë¥¼ ìš°ì•„í•˜ê²Œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
- ì¶”ì¶œ: ì œí’ˆëª…, ë¸Œëœë“œ, ê°€ê²©(ë³´ì´ëŠ” ê²½ìš°), ìƒ‰ìƒ, ì¹˜ìˆ˜(ë³´ì´ëŠ” ê²½ìš°), ëˆˆì— ë³´ì´ëŠ” ê²°í•¨
- ìœ íš¨í•œ JSON ë°˜í™˜ (`json.loads()`ë¡œ íŒŒì‹± ê°€ëŠ¥)
- ì •ë³´ê°€ ë³´ì´ì§€ ì•Šìœ¼ë©´ ë°ì´í„°ë¥¼ ë‚ ì¡°í•˜ì§€ ë§ê³  `null` ì‚¬ìš©
- ê° ì¶”ì¶œëœ í•„ë“œì— ëŒ€í•œ ì‹ ë¢°ë„ ì ìˆ˜ (0-1)

```python
import anthropic
import json

def extract_product_data(image_path: str) -> dict:
    client = anthropic.Anthropic()

    # ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ ì„¤ê³„
    prompt = """???"""

    # êµ¬í˜„
    pass
```

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

```python
import anthropic
import json
import base64
import re

def extract_product_data(image_path: str) -> dict:
    client = anthropic.Anthropic()

    with open(image_path, "rb") as f:
        image_data = base64.standard_b64encode(f.read()).decode("utf-8")

    media_type = "image/jpeg"
    if image_path.endswith(".png"):
        media_type = "image/png"

    prompt = """ì´ ì œí’ˆ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì •í™•íˆ ì´ ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•˜ëŠ” ìœ íš¨í•œ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ì„¸ìš”:
{
  "product_name": string or null,
  "product_name_confidence": number (0.0-1.0),
  "brand": string or null,
  "brand_confidence": number (0.0-1.0),
  "price": string or null,
  "price_confidence": number (0.0-1.0),
  "color": string or null,
  "color_confidence": number (0.0-1.0),
  "dimensions": string or null,
  "dimensions_confidence": number (0.0-1.0),
  "visible_defects": array of strings (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´),
  "defects_confidence": number (0.0-1.0)
}

ê·œì¹™:
1. ì´ë¯¸ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ëŠ” í•„ë“œì—ëŠ” null ì‚¬ìš© â€” ì ˆëŒ€ ë‚ ì¡°í•˜ê±°ë‚˜ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
2. ì‹ ë¢°ë„ ì ìˆ˜ëŠ” ê° í•„ë“œê°€ ì–¼ë§ˆë‚˜ ëª…í™•í•˜ê²Œ ë³´ì´ëŠ”ì§€/ì½íˆëŠ”ì§€ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤:
   - 1.0: ëª…í™•íˆ ë³´ì´ë©° ëª¨í˜¸í•˜ì§€ ì•ŠìŒ
   - 0.7: ë³´ì´ì§€ë§Œ ë¶€ë¶„ì ìœ¼ë¡œ ê°€ë ¤ì§€ê±°ë‚˜ ì¶”ë¡  í•„ìš”
   - 0.4: ë§¥ë½ì—ì„œ ì¶”ë¡ , ì§ì ‘ ë³´ì´ì§€ ì•ŠìŒ
   - null í•„ë“œ â†’ ì‹ ë¢°ë„ ì ìˆ˜ 0.0
3. JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ìŒ
4. ì¹˜ìˆ˜ëŠ” ë³´ì´ëŠ” ê²½ìš° ë‹¨ìœ„ í¬í•¨ (ì˜ˆ: "30cm Ã— 20cm Ã— 10cm")"""

    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": media_type,
                            "data": image_data,
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]
    )

    response_text = message.content[0].text

    # ëª¨ë¸ì´ ì§€ì‹œì—ë„ ë¶ˆêµ¬í•˜ê³  ì¶”ê°€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ëŠ” ê²½ìš°ì—ë„ JSON ì¶”ì¶œ
    json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
    if json_match:
        return json.loads(json_match.group())

    return json.loads(response_text)  # ì§ì ‘ íŒŒì‹±ì„ í´ë°±ìœ¼ë¡œ ì‹œë„
```

í•µì‹¬ ì„¤ê³„ ê²°ì •:
- í”„ë¡¬í”„íŠ¸ì˜ ëª…ì‹œì  ìŠ¤í‚¤ë§ˆëŠ” ëª¨ë¸ì´ í•„ë“œ ì´ë¦„ì„ ì„ì˜ë¡œ ë§Œë“œëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
- ëˆ„ë½ ë°ì´í„°ì— `null` ì‚¬ìš©ì€ ê²€ì¦ë˜ì§€ ì•Šì€ ì •ë³´ì˜ í™˜ê°ì„ ë°©ì§€í•©ë‹ˆë‹¤.
- ì‹ ë¢°ë„ ì ìˆ˜ëŠ” ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë¡œì§ì´ ì–¸ì œ ì‚¬ëŒ ê²€í† ë¥¼ ìœ„í•´ í”Œë˜ê·¸ë¥¼ ì„¸ìš¸ì§€ ê²°ì •í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤(ì˜ˆ: ì‹ ë¢°ë„ < 0.6).
- ì •ê·œì‹(regex) í´ë°±ì€ ëª¨ë¸ì´ ì§€ì‹œì—ë„ ë¶ˆêµ¬í•˜ê³  ì„œë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ëŠ” ê²½ìš°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- í•„ë“œë³„ ê°œë³„ ì‹ ë¢°ë„ ì ìˆ˜ê°€ ë‹¨ì¼ ì „ì²´ ì‹ ë¢°ë„ë³´ë‹¤ ë” ìœ ìš©í•©ë‹ˆë‹¤.

</details>

### ì—°ìŠµ ë¬¸ì œ 4: Gemini ê¸´ ì»¨í…ìŠ¤íŠ¸ ë¹„ë””ì˜¤ ë¶„ì„ ì„¤ê³„
Gemini 1.5 Proë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œë§¤ì ì˜ 8ì‹œê°„ ê°ì‹œ ì˜ìƒì„ ë¶„ì„í•˜ëŠ” í”„ë¡œë•ì…˜ ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ì„¸ìš”. ì‹œìŠ¤í…œì€ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤:
1. ì ˆë„ ì‚¬ê±´ íƒì§€
2. ê³ ê° íë¦„ íŒ¨í„´ ì¶”ì 
3. í”¼í¬ ì‹œê°„ ì‹ë³„
4. ì¼ì¼ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±

ì„¤ê³„ì—ì„œ 2M í† í° ì»¨í…ìŠ¤íŠ¸ ì œí•œ, ë¹„ìš© ê´€ë¦¬, ì¶œë ¥ ì‹ ë¢°ì„±ì„ ë‹¤ë£¨ì„¸ìš”.

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

**ì•„í‚¤í…ì²˜ ì„¤ê³„**:

**ë¬¸ì œ**: 8ì‹œê°„ Ã— 3600ì´ˆ Ã— ~263 í† í°/ì´ˆ â‰ˆ 757ë§Œ í† í° â€” Gemini 1.5 Proì˜ 2M ì»¨í…ìŠ¤íŠ¸ë¥¼ 3.8ë°° ì´ˆê³¼.

**í•´ê²°ì±…: í•µì‹¬ í”„ë ˆì„ ìƒ˜í”Œë§ì„ ì‚¬ìš©í•œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°**:

```python
import google.generativeai as genai
from datetime import datetime, timedelta

class SurveillanceAnalyzer:

    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-pro')
        self.segment_duration = 90 * 60  # 90ë¶„ ì„¸ê·¸ë¨¼íŠ¸ (2M ì»¨í…ìŠ¤íŠ¸ ë‚´)

    def analyze_day(self, video_path: str) -> dict:
        """8ì‹œê°„ ì˜ìƒì„ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬"""
        results = {
            'shoplifting_incidents': [],
            'customer_flow': [],
            'peak_hours': [],
            'summary': ''
        }

        # 10ë¶„ ì˜¤ë²„ë©ìœ¼ë¡œ 90ë¶„ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í• 
        # (ì˜¤ë²„ë©ì€ ì„¸ê·¸ë¨¼íŠ¸ ê²½ê³„ì—ì„œ ì‚¬ê±´ì„ ë†“ì¹˜ì§€ ì•Šë„ë¡ ë°©ì§€)
        segments = self._split_video(video_path, segment_minutes=90, overlap_minutes=10)

        for i, (segment_path, start_time) in enumerate(segments):
            segment_result = self._analyze_segment(segment_path, start_time, i)
            self._merge_results(results, segment_result)

        # ì§‘ê³„ëœ ë°ì´í„°ë¡œ ìµœì¢… í•©ì„± í”„ë¡¬í”„íŠ¸
        results['summary'] = self._generate_summary(results)

        return results

    def _analyze_segment(self, video_path: str, start_time: datetime, segment_idx: int) -> dict:
        """ë‹¨ì¼ 90ë¶„ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„"""

        video_file = self._upload_and_wait(video_path)

        prompt = f"""ì´ ì†Œë§¤ì  ê°ì‹œ ì˜ìƒ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”
        (ì„¸ê·¸ë¨¼íŠ¸ {segment_idx+1}, {start_time.strftime('%H:%M')} ì‹œì‘).

        ë‹¤ìŒì„ ì‹ë³„í•˜ì„¸ìš”:
        1. ì ˆë„(SHOPLIFTING): ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í–‰ë™ (ë¬¼ê±´ ìˆ¨ê¸°ê¸°, ê³„ì‚°ëŒ€ ìš°íšŒ).
           ê° ì‚¬ê±´ì— ëŒ€í•´: íƒ€ì„ìŠ¤íƒ¬í”„, í”„ë ˆì„ ë‚´ ìœ„ì¹˜, ì„¤ëª…, ì‹ ë¢°ë„ (HIGH/MEDIUM/LOW)

        2. ê³ ê°_íë¦„(CUSTOMER_FLOW): 15ë¶„ ê°„ê²©ì˜ ëŒ€ëµì ì¸ ê³ ê° ìˆ˜.
           í˜•ì‹: [{{time: "HH:MM", count: N}}]

        3. ì´ìƒì§•í›„(ANOMALIES): ê¸°íƒ€ ì£¼ëª©í•  ë§Œí•œ ì´ë²¤íŠ¸.

        JSONìœ¼ë¡œ ë°˜í™˜í•˜ë©° í‚¤ëŠ”: shoplifting_incidents, customer_flow, anomalies.
        ì ˆë„ì˜ ê²½ìš° HIGH ë˜ëŠ” MEDIUM ì‹ ë¢°ë„ ì‚¬ê±´ë§Œ ë³´ê³ í•˜ì„¸ìš”.
        """

        response = self.model.generate_content(
            [prompt, video_file],
            generation_config={"temperature": 0.1}  # ì‚¬ì‹¤ì  ë¶„ì„ì„ ìœ„í•œ ë‚®ì€ ì˜¨ë„
        )

        return self._parse_response(response.text, start_time)

    def _generate_summary(self, results: dict) -> str:
        """ì§‘ê³„ëœ ê²°ê³¼ì—ì„œ ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""

        summary_prompt = f"""ì˜¤ëŠ˜ì˜ ì†Œë§¤ì  ê°ì‹œ ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ:

        - íƒì§€ëœ ì‚¬ê±´: {len(results['shoplifting_incidents'])}
        - ì¶”ì ëœ ì´ ê³ ê° ìˆ˜: {sum(h['count'] for h in results['customer_flow'])}
        - í”¼í¬ ì‹œê°„ëŒ€: {self._find_peak(results['customer_flow'])}

        ë§¤ì¥ ê´€ë¦¬ìë¥¼ ìœ„í•œ ê°„ê²°í•œ ì¼ì¼ ë³´ì•ˆ ë° ìš´ì˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        ì§ì› ë°°ì¹˜ ì¡°ì • ë° ë³´ì•ˆ ì§‘ì¤‘ ì˜ì—­ì— ëŒ€í•œ ê¶Œì¥ ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”."""

        # í…ìŠ¤íŠ¸ ì „ìš© ìµœì¢… í•©ì„± (ë¹„ë””ì˜¤ ì¬ì—…ë¡œë“œ ë¶ˆí•„ìš”)
        response = self.model.generate_content(summary_prompt)
        return response.text
```

**ë¹„ìš© ê´€ë¦¬**:
- 8ì‹œê°„ Ã— 263 í† í°/ì´ˆ = 757ë§Œ ì…ë ¥ í† í°
- $1.25/1M í† í°ìœ¼ë¡œ = ë¹„ë””ì˜¤ ì²˜ë¦¬ì— í•˜ë£¨ ì•½ $9.46
- í…ìŠ¤íŠ¸ ì¶œë ¥ ì¶”ê°€: ~$5.00/1M Ã— ì•½ 2ë§Œ ì¶œë ¥ í† í° = ì•½ $0.10
- ì´ê³„ â‰ˆ $9.56/ì¼ â€” í”„ë ˆì„ ë ˆì´íŠ¸ ê°ì†Œ(ì›ë³¸ ëŒ€ì‹  1fps)ë¡œ 50-75% ë¹„ìš© ì ˆê° ê°€ëŠ¥

**ì‹ ë¢°ì„± ê°œì„ **:
- ì‚¬ì‹¤ì  ë¶„ì„ì„ ìœ„í•œ ë‚®ì€ ì˜¨ë„(0.1)ë¡œ ë‚ ì¡°ëœ ì‚¬ê±´ ê°ì†Œ.
- HIGH/MEDIUM ì‹ ë¢°ë„ ì‚¬ê±´ë§Œ ë³´ê³ í•˜ì—¬ ê±°ì§“ ì–‘ì„±(false positive) ê°ì†Œ.
- 10ë¶„ ì˜¤ë²„ë© ì„¸ê·¸ë¨¼íŠ¸ë¡œ ê²½ê³„ì—ì„œ ì‚¬ê±´ì„ ë†“ì¹˜ì§€ ì•Šë„ë¡ ë³´ì¥.
- ìµœì¢… í•©ì„± ë‹¨ê³„(í…ìŠ¤íŠ¸ ì „ìš©)ë¡œ ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ ë¹„ë””ì˜¤ ì¬ì—…ë¡œë“œ ë°©ì§€.

</details>
