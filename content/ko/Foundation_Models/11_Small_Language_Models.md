# 11. Small Language Models

## í•™ìŠµ ëª©í‘œ(Learning Objectives)

ì´ ë ˆìŠ¨ì„ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. ì§€ì—° ì‹œê°„, í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­, ê³¼ì œ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ì—£ì§€(Edge) ë°°í¬, ë¹„ìš© ë¯¼ê°í•œ ì• í”Œë¦¬ì¼€ì´ì…˜, ê°œì¸ì •ë³´ ë³´í˜¸ê°€ ì¤‘ìš”í•œ ë„ë©”ì¸ì—ì„œ ëŒ€í˜• ëª¨ë¸ ëŒ€ì‹  ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ ë¥¼ ì •ë‹¹í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. Phi-3, Gemma 2, Qwen 2.5ì™€ ê°™ì€ ì£¼ìš” SLMì´ ì†Œê·œëª¨ì—ì„œ ì„±ëŠ¥ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì•„í‚¤í…ì²˜ ì„ íƒê³¼ í•™ìŠµ ë°ì´í„° ì „ëµ(ì˜ˆ: "êµê³¼ì„œë§Œ ìˆìœ¼ë©´ ì¶©ë¶„í•˜ë‹¤")ì„ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ì–‘ìí™”(Quantization, GPTQ, AWQ, GGUF), í”„ë£¨ë‹(Pruning), ì§€ì‹ ì¦ë¥˜(Knowledge Distillation) ë“±ì˜ ëª¨ë¸ ì••ì¶• ê¸°ë²•ì„ ì ìš©í•˜ì—¬ SLMì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì¶”ë¡  ì§€ì—° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. llama.cpp, Ollama, ExLlamaV2 ë“±ì˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ SLM íš¨ìœ¨ì  ì¶”ë¡ ì„ êµ¬í˜„í•˜ê³ , ì²˜ë¦¬ëŸ‰ê³¼ ì§€ì—° ì‹œê°„ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ë²¤ì¹˜ë§ˆí¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
5. LoRA, QLoRAì™€ ê°™ì€ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë°©ë²•(Parameter-Efficient Fine-tuning)ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ë„ë©”ì¸ì´ë‚˜ ê³¼ì œì— ë§ê²Œ SLMì„ íŒŒì¸íŠœë‹í•˜ê³ , ê¸°ë³¸ ëª¨ë¸ ëŒ€ë¹„ ê°œì„  íš¨ê³¼ë¥¼ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
6. ê³¼ì œ ë³µì¡ì„±, ë¹„ìš© ì œì•½, ì§€ì—° ì‹œê°„ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ SLMê³¼ LLM ê°„ì— ë¼ìš°íŒ…í•˜ëŠ” ë°°í¬ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ê°œìš”

ëŒ€í˜• ëª¨ë¸(100B+)ì´ í™”ì œì§€ë§Œ, ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” **Small Language Models (SLM)**ì´ ë” ì‹¤ìš©ì ì…ë‹ˆë‹¤. ì´ ë ˆìŠ¨ì—ì„œëŠ” 7B ì´í•˜ ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜, í•™ìŠµ ì „ëµ, í™œìš© ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

---

## 1. SLMì˜ ì¤‘ìš”ì„±

### 1.1 ì™œ ì‘ì€ ëª¨ë¸ì¸ê°€?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SLM vs LLM ë¹„êµ                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚                    SLM (1-7B)              LLM (70B+)            â”‚
â”‚                                                                  â”‚
â”‚  ğŸ’° ë¹„ìš©          ë‚®ìŒ                      ë†’ìŒ                 â”‚
â”‚  âš¡ ì§€ì—°ì‹œê°„      ë‚®ìŒ (<100ms)             ë†’ìŒ (>500ms)        â”‚
â”‚  ğŸ–¥ï¸ í•˜ë“œì›¨ì–´     ë‹¨ì¼ GPU/CPU             ë‹¤ì¤‘ GPU í•„ìˆ˜        â”‚
â”‚  ğŸ“± ì—£ì§€ ë°°í¬    ê°€ëŠ¥                      ì–´ë ¤ì›€               â”‚
â”‚  ğŸ”’ í”„ë¼ì´ë²„ì‹œ   ì˜¨í”„ë ˆë¯¸ìŠ¤ ì‰¬ì›€           ì–´ë ¤ì›€               â”‚
â”‚  ğŸ¯ íŠ¹í™” íƒœìŠ¤í¬  ë¹„ìš© íš¨ìœ¨ì                ê³¼ì‰                 â”‚
â”‚                                                                  â”‚
â”‚  ì‚¬ìš© ì‚¬ë¡€:                                                      â”‚
â”‚  - ëª¨ë°”ì¼ ì•± (On-device)                                        â”‚
â”‚  - ì„ë² ë””ë“œ ì‹œìŠ¤í…œ                                              â”‚
â”‚  - ê³ ë¹ˆë„ API ì„œë¹„ìŠ¤                                            â”‚
â”‚  - ë¹„ìš© ë¯¼ê°í•œ ìŠ¤íƒ€íŠ¸ì—…                                         â”‚
â”‚  - ê°œì¸ì •ë³´ ë³´í˜¸ê°€ ì¤‘ìš”í•œ ë„ë©”ì¸                                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 SLM ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | í•™ìŠµ í† í° | íŠ¹ì§• |
|------|----------|-----------|------|
| **Phi-3** | 3.8B | 3.3T | MS, ì¶”ë¡  íŠ¹í™” |
| **Gemma 2** | 2B / 9B | 8T | Google, ì½”ë“œ ê°•ì  |
| **Qwen 2.5** | 0.5B - 7B | 18T | ë‹¤êµ­ì–´, ìˆ˜í•™ |
| **Llama 3.2** | 1B / 3B | 15T | ëª¨ë°”ì¼ ìµœì í™” |
| **TinyLlama** | 1.1B | 3T | íš¨ìœ¨ì  í•™ìŠµ |
| **StableLM 2** | 1.6B | 2T | Stability AI |
| **SmolLM** | 135M - 1.7B | 1T | HuggingFace |

---

## 2. ì•„í‚¤í…ì²˜ ìµœì í™”

### 2.1 Phi ì‹œë¦¬ì¦ˆ (Microsoft)

```python
"""
Phi-3: "Textbooks Are All You Need" ì² í•™

í•µì‹¬ ì•„ì´ë””ì–´:
1. ë°ì´í„° í’ˆì§ˆ > ë°ì´í„° ì–‘
2. í•©ì„± ë°ì´í„° í™œìš© (GPT-4ë¡œ ìƒì„±)
3. êµê³¼ì„œê¸‰ í’ˆì§ˆì˜ ë°ì´í„°ë§Œ ì‚¬ìš©

ê²°ê³¼: 3.8Bë¡œ GPT-3.5ê¸‰ ì¶”ë¡  ëŠ¥ë ¥
"""

class Phi3Config:
    """Phi-3 ì•„í‚¤í…ì²˜ ì„¤ì •"""

    # Phi-3-mini (3.8B)
    hidden_size = 3072
    num_layers = 32
    num_attention_heads = 32
    num_key_value_heads = 32  # No GQA
    intermediate_size = 8192  # FFN í™•ì¥ë¹„ ~2.7x
    vocab_size = 32064
    max_position_embeddings = 4096  # í™•ì¥ ê°€ëŠ¥

    # íŠ¹ì§•
    # - SuRoPE (Scaled RoPE)
    # - LayerNorm (RMSNorm ëŒ€ì‹ )
    # - SwiGLU FFN


# Phi-3 ì‚¬ìš© ì˜ˆì‹œ
from transformers import AutoModelForCausalLM, AutoTokenizer

def use_phi3():
    model = AutoModelForCausalLM.from_pretrained(
        "microsoft/Phi-3-mini-4k-instruct",
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True
    )
    tokenizer = AutoTokenizer.from_pretrained(
        "microsoft/Phi-3-mini-4k-instruct"
    )

    # ì¶”ë¡ 
    messages = [
        {"role": "user", "content": "Explain the Pythagorean theorem."}
    ]

    inputs = tokenizer.apply_chat_template(
        messages, return_tensors="pt", return_dict=True
    ).to(model.device)

    outputs = model.generate(
        **inputs,
        max_new_tokens=256,
        temperature=0.7
    )

    return tokenizer.decode(outputs[0])
```

### 2.2 Gemma 2 (Google)

```python
"""
Gemma 2: íš¨ìœ¨ì ì¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

í•µì‹¬ íŠ¹ì§•:
1. Alternating Local-Global Attention
2. Soft-Capping (Logits & Attention)
3. Pre-Norm + Post-Norm hybrid
4. Knowledge Distillation from larger models
"""

class Gemma2Config:
    """Gemma 2 ì•„í‚¤í…ì²˜"""

    # Gemma 2 2B
    hidden_size = 2304
    num_layers = 26
    num_attention_heads = 8
    num_key_value_heads = 4  # GQA ì‚¬ìš©
    intermediate_size = 9216
    vocab_size = 256128  # í° vocab

    # Gemma 2 9B
    # hidden_size = 3584
    # num_layers = 42
    # num_attention_heads = 16
    # num_key_value_heads = 8


class GemmaAttentionWithSoftCap(nn.Module):
    """Gemma 2 ìŠ¤íƒ€ì¼ Soft-Capping Attention"""

    def __init__(self, config, layer_idx: int):
        super().__init__()
        self.config = config
        self.layer_idx = layer_idx

        # Local vs Global attention êµëŒ€
        # ì§ìˆ˜ ë ˆì´ì–´: Local (sliding window)
        # í™€ìˆ˜ ë ˆì´ì–´: Global (full attention)
        self.is_local = (layer_idx % 2 == 0)
        self.sliding_window = 4096 if self.is_local else None

        # Soft-cap ê°’
        self.attn_logit_softcap = 50.0

        # Projections
        self.q_proj = nn.Linear(config.hidden_size, config.hidden_size)
        self.k_proj = nn.Linear(config.hidden_size, config.hidden_size // 2)  # GQA
        self.v_proj = nn.Linear(config.hidden_size, config.hidden_size // 2)
        self.o_proj = nn.Linear(config.hidden_size, config.hidden_size)

    def forward(self, hidden_states, attention_mask=None):
        batch, seq_len, _ = hidden_states.shape

        Q = self.q_proj(hidden_states)
        K = self.k_proj(hidden_states)
        V = self.v_proj(hidden_states)

        # GQA: K, V í™•ì¥
        K = K.repeat_interleave(2, dim=-1)  # ê°„ì†Œí™”
        V = V.repeat_interleave(2, dim=-1)

        # Attention scores
        scores = torch.matmul(Q, K.transpose(-2, -1))
        scores = scores / math.sqrt(Q.shape[-1])

        # Soft-capping: tanhë¡œ ë²”ìœ„ ì œí•œ
        scores = self.attn_logit_softcap * torch.tanh(scores / self.attn_logit_softcap)

        # Sliding window mask (local attention)
        if self.is_local and self.sliding_window:
            mask = self._create_sliding_window_mask(seq_len)
            scores = scores + mask

        # Causal mask
        causal_mask = torch.triu(
            torch.ones(seq_len, seq_len) * float('-inf'),
            diagonal=1
        ).to(scores.device)
        scores = scores + causal_mask

        weights = F.softmax(scores, dim=-1)
        output = torch.matmul(weights, V)

        return self.o_proj(output)

    def _create_sliding_window_mask(self, seq_len):
        """Sliding window attention mask"""
        mask = torch.ones(seq_len, seq_len) * float('-inf')
        for i in range(seq_len):
            start = max(0, i - self.sliding_window)
            mask[i, start:i+1] = 0
        return mask
```

### 2.3 Qwen 2.5 (Alibaba)

```python
"""
Qwen 2.5: ë‹¤êµ­ì–´ & ìˆ˜í•™ ê°•ì 

íŠ¹ì§•:
1. ëŒ€ê·œëª¨ ë‹¤êµ­ì–´ í•™ìŠµ (29ê°œ ì–¸ì–´)
2. ì½”ë“œ/ìˆ˜í•™ íŠ¹í™” ë°ì´í„°
3. ê¸´ ì»¨í…ìŠ¤íŠ¸ (128K)
4. ë‹¤ì–‘í•œ í¬ê¸° (0.5B ~ 72B)
"""

class Qwen25Config:
    """Qwen 2.5 ì•„í‚¤í…ì²˜"""

    # Qwen2.5-0.5B (ê°€ì¥ ì‘ì€ ë²„ì „)
    hidden_size = 896
    num_layers = 24
    num_attention_heads = 14
    num_key_value_heads = 2  # íš¨ìœ¨ì  GQA
    intermediate_size = 4864
    vocab_size = 151936

    # Qwen2.5-7B
    # hidden_size = 3584
    # num_layers = 28
    # num_attention_heads = 28
    # num_key_value_heads = 4


# Qwen ì‚¬ìš© ì˜ˆì‹œ
def use_qwen():
    from transformers import AutoModelForCausalLM, AutoTokenizer

    model = AutoModelForCausalLM.from_pretrained(
        "Qwen/Qwen2.5-0.5B-Instruct",
        torch_dtype="auto",
        device_map="auto"
    )
    tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")

    # ë‹¤êµ­ì–´ í…ŒìŠ¤íŠ¸
    prompts = [
        "Explain machine learning in simple terms.",
        "ç”¨ç®€å•çš„è¯è§£é‡Šæœºå™¨å­¦ä¹ ",  # ì¤‘êµ­ì–´
        "ê¸°ê³„ í•™ìŠµì„ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”",  # í•œêµ­ì–´
    ]

    for prompt in prompts:
        messages = [{"role": "user", "content": prompt}]
        text = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        inputs = tokenizer([text], return_tensors="pt").to(model.device)
        outputs = model.generate(**inputs, max_new_tokens=128)
        print(tokenizer.decode(outputs[0], skip_special_tokens=True))
        print("-" * 50)
```

---

## 3. í•™ìŠµ ì „ëµ

### 3.1 ë°ì´í„° í’ˆì§ˆ vs ì–‘

```python
"""
SLM í•™ìŠµì˜ í•µì‹¬: ê³ í’ˆì§ˆ ë°ì´í„°

Phiì˜ êµí›ˆ:
- ì›¹ í¬ë¡¤ë§ ë°ì´í„° (í’ˆì§ˆ ë‚®ìŒ) < êµê³¼ì„œê¸‰ ë°ì´í„°
- í•©ì„± ë°ì´í„° (GPT-4 ìƒì„±)ê°€ íš¨ê³¼ì 
- í•„í„°ë§ì´ ë§¤ìš° ì¤‘ìš”
"""

class HighQualityDataPipeline:
    """ê³ í’ˆì§ˆ ë°ì´í„° íŒŒì´í”„ë¼ì¸"""

    def __init__(self, quality_model):
        self.quality_model = quality_model

    def filter_data(self, texts: list, threshold: float = 0.8):
        """í’ˆì§ˆ ê¸°ë°˜ í•„í„°ë§"""
        filtered = []
        for text in texts:
            score = self.quality_model.score(text)
            if score > threshold:
                filtered.append(text)

        print(f"Filtered: {len(texts)} â†’ {len(filtered)}")
        return filtered

    def generate_synthetic_data(
        self,
        teacher_model,
        topics: list,
        n_samples: int = 10000
    ):
        """í•©ì„± ë°ì´í„° ìƒì„±"""
        synthetic_data = []

        for topic in topics:
            prompt = f"""Create an educational explanation about {topic}.
            The explanation should be:
            1. Clear and concise
            2. Include examples
            3. Suitable for learning"""

            for _ in range(n_samples // len(topics)):
                response = teacher_model.generate(prompt)

                # í’ˆì§ˆ ê²€ì¦
                if self._validate_response(response):
                    synthetic_data.append({
                        'topic': topic,
                        'content': response
                    })

        return synthetic_data

    def _validate_response(self, response: str) -> bool:
        """ì‘ë‹µ í’ˆì§ˆ ê²€ì¦"""
        # ê¸¸ì´ ì²´í¬
        if len(response.split()) < 50:
            return False

        # ë°˜ë³µ ì²´í¬
        sentences = response.split('.')
        if len(set(sentences)) / len(sentences) < 0.8:
            return False

        return True
```

### 3.2 Knowledge Distillation

```python
"""
Knowledge Distillation: í° ëª¨ë¸ â†’ ì‘ì€ ëª¨ë¸

Teacher (ëŒ€í˜• ëª¨ë¸)ì˜ ì§€ì‹ì„ Student (SLM)ì—ê²Œ ì „ë‹¬
"""

class DistillationTrainer:
    """KD ê¸°ë°˜ SLM í•™ìŠµ"""

    def __init__(
        self,
        teacher_model,  # ì˜ˆ: Llama 70B
        student_model,  # ì˜ˆ: 3B ëª¨ë¸
        temperature: float = 2.0,
        alpha: float = 0.5  # soft/hard loss ë¹„ìœ¨
    ):
        self.teacher = teacher_model
        self.student = student_model
        self.temperature = temperature
        self.alpha = alpha

        # TeacherëŠ” í•™ìŠµ ì•ˆ í•¨
        self.teacher.eval()
        for param in self.teacher.parameters():
            param.requires_grad = False

    def distillation_loss(
        self,
        student_logits: torch.Tensor,
        teacher_logits: torch.Tensor,
        labels: torch.Tensor
    ) -> torch.Tensor:
        """
        Distillation Loss = Î± Ã— Soft Loss + (1-Î±) Ã— Hard Loss

        Soft Loss: KL(student_soft || teacher_soft)
        Hard Loss: CrossEntropy(student, labels)
        """
        T = self.temperature

        # Soft targets (temperature scaling)
        teacher_soft = F.softmax(teacher_logits / T, dim=-1)
        student_soft = F.log_softmax(student_logits / T, dim=-1)

        # KL Divergence (soft loss)
        soft_loss = F.kl_div(
            student_soft,
            teacher_soft,
            reduction='batchmean'
        ) * (T ** 2)  # Temperature scaling ë³´ì •

        # Cross Entropy (hard loss)
        hard_loss = F.cross_entropy(
            student_logits.view(-1, student_logits.size(-1)),
            labels.view(-1),
            ignore_index=-100
        )

        # Combined loss
        loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss

        return loss

    def train_step(self, batch):
        """í•™ìŠµ ìŠ¤í…"""
        input_ids = batch['input_ids']
        labels = batch['labels']

        # Teacher forward (no grad)
        with torch.no_grad():
            teacher_outputs = self.teacher(input_ids)
            teacher_logits = teacher_outputs.logits

        # Student forward
        student_outputs = self.student(input_ids)
        student_logits = student_outputs.logits

        # Distillation loss
        loss = self.distillation_loss(
            student_logits, teacher_logits, labels
        )

        return loss


# Response-level Distillation (ë” íš¨ê³¼ì )
class ResponseDistillation:
    """ì‘ë‹µ ìˆ˜ì¤€ KD"""

    def __init__(self, teacher_model, student_model):
        self.teacher = teacher_model
        self.student = student_model

    def generate_training_data(self, prompts: list):
        """Teacher ì‘ë‹µìœ¼ë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±"""
        training_data = []

        for prompt in prompts:
            # Teacher ì‘ë‹µ ìƒì„±
            teacher_response = self.teacher.generate(
                prompt,
                max_new_tokens=512,
                temperature=0.7
            )

            training_data.append({
                'prompt': prompt,
                'response': teacher_response
            })

        return training_data

    def train_on_responses(self, training_data):
        """Teacher ì‘ë‹µìœ¼ë¡œ Student í•™ìŠµ"""
        # Standard SFT (Supervised Fine-Tuning)
        for item in training_data:
            full_text = f"{item['prompt']}\n{item['response']}"
            # ... SFT í•™ìŠµ
```

### 3.3 íš¨ìœ¨ì  í•™ìŠµ ê¸°ë²•

```python
"""
SLM í•™ìŠµ íš¨ìœ¨í™” ê¸°ë²•
"""

# 1. Gradient Accumulation (ì‘ì€ ë°°ì¹˜ë¡œ í° effective batch)
def train_with_grad_accumulation(
    model,
    dataloader,
    accumulation_steps: int = 8
):
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

    for i, batch in enumerate(dataloader):
        outputs = model(**batch)
        loss = outputs.loss / accumulation_steps
        loss.backward()

        if (i + 1) % accumulation_steps == 0:
            optimizer.step()
            optimizer.zero_grad()


# 2. LoRAë¡œ íš¨ìœ¨ì  fine-tuning
from peft import LoraConfig, get_peft_model

def setup_lora_training(model):
    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
        lora_dropout=0.1,
        bias="none"
    )

    model = get_peft_model(model, lora_config)

    # í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„° í™•ì¸
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total = sum(p.numel() for p in model.parameters())
    print(f"Trainable: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)")

    return model


# 3. QLoRA (ì–‘ìí™” + LoRA)
from transformers import BitsAndBytesConfig

def setup_qlora_training(model_name):
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
        bnb_4bit_use_double_quant=True,
    )

    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=bnb_config,
        device_map="auto"
    )

    # LoRA ì¶”ê°€
    return setup_lora_training(model)
```

---

## 4. ë°°í¬ ìµœì í™”

### 4.1 ì–‘ìí™”

```python
"""
SLM ì–‘ìí™”: ë©”ëª¨ë¦¬ & ì†ë„ ìµœì í™”
"""

# 1. GPTQ (Post-Training Quantization)
from transformers import GPTQConfig

def quantize_with_gptq(model_name):
    gptq_config = GPTQConfig(
        bits=4,
        dataset="c4",
        tokenizer=AutoTokenizer.from_pretrained(model_name)
    )

    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=gptq_config,
        device_map="auto"
    )

    return model


# 2. AWQ (Activation-aware Weight Quantization)
from awq import AutoAWQForCausalLM

def quantize_with_awq(model_path, output_path):
    model = AutoAWQForCausalLM.from_pretrained(model_path)
    tokenizer = AutoTokenizer.from_pretrained(model_path)

    # ì–‘ìí™”
    model.quantize(
        tokenizer,
        quant_config={
            "zero_point": True,
            "q_group_size": 128,
            "w_bit": 4,
            "version": "GEMM"
        }
    )

    # ì €ì¥
    model.save_quantized(output_path)


# 3. llama.cpp (GGUF í¬ë§·)
"""
llama.cpp ì–‘ìí™” ë ˆë²¨:
- Q2_K: 2ë¹„íŠ¸ (ë§¤ìš° ì‘ìŒ, í’ˆì§ˆ ì €í•˜)
- Q4_K_M: 4ë¹„íŠ¸ (ê¶Œì¥, í’ˆì§ˆ/í¬ê¸° ê· í˜•)
- Q5_K_M: 5ë¹„íŠ¸ (ë†’ì€ í’ˆì§ˆ)
- Q8_0: 8ë¹„íŠ¸ (ê±°ì˜ ì›ë³¸ í’ˆì§ˆ)

ëª…ë ¹ì–´:
./quantize model.gguf model-q4_k_m.gguf Q4_K_M
"""


# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
def compare_memory_usage():
    """íŒŒë¼ë¯¸í„° ìˆ˜ì— ë”°ë¥¸ ë©”ëª¨ë¦¬"""
    configs = [
        ("3B FP16", 3e9 * 2),       # 6GB
        ("3B Q8", 3e9 * 1),         # 3GB
        ("3B Q4", 3e9 * 0.5),       # 1.5GB
        ("7B FP16", 7e9 * 2),       # 14GB
        ("7B Q4", 7e9 * 0.5),       # 3.5GB
    ]

    print("Model\t\tMemory (GB)")
    print("-" * 30)
    for name, memory in configs:
        print(f"{name}\t\t{memory / 1e9:.1f}")
```

### 4.2 On-Device ë°°í¬

```python
"""
ëª¨ë°”ì¼/ì—£ì§€ ë””ë°”ì´ìŠ¤ ë°°í¬
"""

# 1. ONNX ë³€í™˜
def convert_to_onnx(model, tokenizer, output_path):
    from optimum.onnxruntime import ORTModelForCausalLM

    # ONNX ë³€í™˜ ë° ìµœì í™”
    ort_model = ORTModelForCausalLM.from_pretrained(
        model,
        export=True,
        provider="CPUExecutionProvider"
    )

    ort_model.save_pretrained(output_path)


# 2. TensorRT-LLM (NVIDIA GPU)
"""
TensorRT-LLM ì‚¬ìš©:
1. ëª¨ë¸ ë³€í™˜: python convert_checkpoint.py
2. ì—”ì§„ ë¹Œë“œ: trtllm-build
3. ì¶”ë¡ : python run.py
"""


# 3. llama.cpp (CPU ì¶”ë¡ )
"""
llama.cpp ì‚¬ìš©:
1. GGUF ë³€í™˜
2. llama-cli ì‹¤í–‰

./llama-cli -m model.gguf \
    -n 256 \
    -p "Hello, how are you?" \
    -t 4  # threads
"""


# 4. MLC-LLM (ë‹¤ì–‘í•œ í”Œë«í¼)
"""
MLC-LLM: iOS, Android, WebGPU, CUDA

mlc_chat ì•±ìœ¼ë¡œ ëª¨ë°”ì¼ ë°°í¬ ê°€ëŠ¥
"""
```

---

## 5. ë²¤ì¹˜ë§ˆí¬ & í‰ê°€

### 5.1 SLM ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            SLM ë²¤ì¹˜ë§ˆí¬ ë¹„êµ (2024.10 ê¸°ì¤€)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Model          Params  MMLU    GSM8K   HumanEval  TriviaQA     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Phi-3-mini     3.8B    69.9%   82.5%   57.9%      63.5%        â”‚
â”‚  Gemma-2-9B     9B      71.3%   68.6%   54.3%      73.5%        â”‚
â”‚  Qwen2.5-7B     7B      74.2%   82.6%   75.6%      71.4%        â”‚
â”‚  Llama-3.2-3B   3B      63.4%   44.4%   36.0%      63.4%        â”‚
â”‚  SmolLM-1.7B    1.7B    42.3%   18.2%   28.7%      42.1%        â”‚
â”‚                                                                  â”‚
â”‚  ì°¸ê³ : GPT-4    -       86.4%   92.0%   67.0%      87.6%        â”‚
â”‚                                                                  â”‚
â”‚  â€» Phi-3ì€ ì‘ì€ í¬ê¸° ëŒ€ë¹„ ë›°ì–´ë‚œ ì¶”ë¡  ëŠ¥ë ¥                       â”‚
â”‚  â€» Qwen2.5ëŠ” ì½”ë“œ(HumanEval)ì—ì„œ ê°•ì                             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 íƒœìŠ¤í¬ë³„ SLM ì„ íƒ ê°€ì´ë“œ

```python
"""
íƒœìŠ¤í¬ë³„ SLM ì¶”ì²œ
"""

TASK_MODEL_RECOMMENDATIONS = {
    # ì¼ë°˜ ëŒ€í™”
    "general_chat": {
        "best": "Qwen2.5-7B-Instruct",
        "budget": "Qwen2.5-1.5B-Instruct",
        "mobile": "Qwen2.5-0.5B-Instruct"
    },

    # ì½”ë“œ ìƒì„±
    "code_generation": {
        "best": "Qwen2.5-Coder-7B",
        "budget": "CodeGemma-2B",
        "mobile": "Phi-3-mini"
    },

    # ìˆ˜í•™/ì¶”ë¡ 
    "math_reasoning": {
        "best": "Qwen2.5-Math-7B",
        "budget": "Phi-3-mini",
        "mobile": "Phi-3-mini"
    },

    # í•œêµ­ì–´
    "korean": {
        "best": "Qwen2.5-7B-Instruct",  # ë‹¤êµ­ì–´ ê°•ì 
        "budget": "EXAONE-3.0-7.8B-Instruct",
        "mobile": "Qwen2.5-1.5B-Instruct"
    },

    # RAG/ê²€ìƒ‰
    "rag": {
        "best": "Gemma-2-9B",
        "budget": "Llama-3.2-3B",
        "mobile": "Phi-3-mini"
    },

    # ìš”ì•½
    "summarization": {
        "best": "Qwen2.5-7B-Instruct",
        "budget": "Gemma-2-2B",
        "mobile": "SmolLM-1.7B"
    }
}


def select_model(task: str, constraint: str = "best"):
    """íƒœìŠ¤í¬ì™€ ì œì•½ì— ë§ëŠ” ëª¨ë¸ ì„ íƒ"""
    if task in TASK_MODEL_RECOMMENDATIONS:
        return TASK_MODEL_RECOMMENDATIONS[task].get(constraint)
    return "Qwen2.5-7B-Instruct"  # ê¸°ë³¸ê°’
```

---

## 6. ì‹¤ìŠµ: SLM Fine-tuning

```python
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    BitsAndBytesConfig
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from datasets import load_dataset

def finetune_slm():
    """SLM QLoRA Fine-tuning ì˜ˆì œ"""

    # 1. ëª¨ë¸ ë¡œë“œ (4ë¹„íŠ¸ ì–‘ìí™”)
    model_name = "Qwen/Qwen2.5-1.5B-Instruct"

    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
    )

    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=bnb_config,
        device_map="auto"
    )

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    tokenizer.pad_token = tokenizer.eos_token

    # 2. LoRA ì„¤ì •
    model = prepare_model_for_kbit_training(model)

    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                       "gate_proj", "up_proj", "down_proj"],
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM"
    )

    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()

    # 3. ë°ì´í„°ì…‹
    dataset = load_dataset("timdettmers/openassistant-guanaco")

    def preprocess(examples):
        texts = []
        for text in examples['text']:
            # Qwen chat format
            texts.append(text + tokenizer.eos_token)

        tokenized = tokenizer(
            texts,
            truncation=True,
            max_length=1024,
            padding="max_length"
        )
        tokenized['labels'] = tokenized['input_ids'].copy()
        return tokenized

    tokenized_dataset = dataset['train'].map(
        preprocess,
        batched=True,
        remove_columns=dataset['train'].column_names
    )

    # 4. í•™ìŠµ
    training_args = TrainingArguments(
        output_dir="./qwen-finetuned",
        per_device_train_batch_size=4,
        gradient_accumulation_steps=4,
        num_train_epochs=3,
        learning_rate=2e-4,
        lr_scheduler_type="cosine",
        warmup_ratio=0.03,
        logging_steps=10,
        save_steps=500,
        bf16=True,
        optim="paged_adamw_8bit"
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_dataset,
        tokenizer=tokenizer,
    )

    trainer.train()

    # 5. ì €ì¥
    model.save_pretrained("./qwen-lora-adapter")

    print("Fine-tuning complete!")


if __name__ == "__main__":
    finetune_slm()
```

---

## ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- Gunasekar et al. (2023). "Textbooks Are All You Need" (Phi)
- Gemma Team (2024). "Gemma 2: Improving Open Language Models"
- Yang et al. (2024). "Qwen2 Technical Report"

### ëª¨ë¸
- [Phi-3](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)
- [Gemma 2](https://huggingface.co/google/gemma-2-9b)
- [Qwen 2.5](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)
- [Llama 3.2](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)

### ê´€ë ¨ ë ˆìŠ¨
- [../LLM_and_NLP/11_Model_Quantization.md](../LLM_and_NLP/11_Model_Quantization.md)
- [19_PEFT_Unified.md](19_PEFT_Unified.md)

---

## ì—°ìŠµ ë¬¸ì œ

### ì—°ìŠµ ë¬¸ì œ 1: SLM ì‚¬ìš© ì‚¬ë¡€ ë¶„ì„

ê° ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ SLM(â‰¤7B) ë˜ëŠ” LLM(70B+) ì¤‘ ì–´ëŠ ê²ƒì´ ë” ì í•©í•œì§€ ê²°ì •í•˜ê³ , ìµœì†Œ ë‘ ê°€ì§€ ì´ìœ ë¡œ ë‹µë³€ì„ ì •ë‹¹í™”í•˜ì„¸ìš”.

1. ì¸í„°ë„· ì—°ê²° ì—†ì´ ìŠ¤ë§ˆíŠ¸í°ì—ì„œ ì‹¤í–‰ë˜ì–´ ì…ë ¥ ì¤‘ ì‹¤ì‹œê°„ ë¬¸ë²• êµì •ì„ ì œê³µí•˜ëŠ” ëª¨ë°”ì¼ ì•±.
2. 50ê°œ ì´ìƒì˜ ê´€í• ê¶Œì—ì„œ ê·œì • ì¤€ìˆ˜ ë¬¸ì œì— ëŒ€í•´ 200í˜ì´ì§€ ê³„ì•½ì„œë¥¼ ë¶„ì„í•´ì•¼ í•˜ëŠ” ë²•ë¥  íšŒì‚¬ì˜ ë¬¸ì„œ ê²€í†  ì‹œìŠ¤í…œ.
3. í™˜ë¶ˆ ìš”ì²­, ì£¼ë¬¸ ì¶”ì , ì œí’ˆ FAQë¥¼ ì²˜ë¦¬í•˜ëŠ” ë‹¨ì¼ ì´ì»¤ë¨¸ìŠ¤ í”Œë«í¼ì˜ ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡.
4. ì „ë¬¸ ë¶„ì•¼ì˜ 500ê°œ ì´ìƒì˜ ìµœê·¼ ë…¼ë¬¸ì—ì„œ ë°œê²¬ ì‚¬í•­ì„ ì¢…í•©í•´ì•¼ í•˜ëŠ” ê³¼í•™ ì—°êµ¬ ë³´ì¡° ì‹œìŠ¤í…œ.

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

**1. ëª¨ë°”ì¼ ë¬¸ë²• êµì • â†’ SLM**
- **ê°œì¸ì •ë³´ ë³´í˜¸**: ê°œì¸ ë©”ì‹œì§€ì˜ ë¬¸ë²• êµì •ì€ ê¸°ê¸°ë¥¼ ë²—ì–´ë‚˜ë©´ ì•ˆ ë©ë‹ˆë‹¤; ì˜¨ë””ë°”ì´ìŠ¤ ì¶”ë¡ ì€ ì‘ì€ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
- **ì§€ì—° ì‹œê°„**: ì‹¤ì‹œê°„ êµì •(< 100ms)ì€ ëª¨ë°”ì¼ CPU/NPUì—ì„œ ë¹ ë¥´ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤; 70B ëª¨ë¸ì€ ë¬¼ë¦¬ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
- **í•˜ë“œì›¨ì–´ ì œì•½**: ìŠ¤ë§ˆíŠ¸í°ì€ 6-16GB RAMì„ ê°€ì§‘ë‹ˆë‹¤; 4ë¹„íŠ¸ë¡œ ì–‘ìí™”ëœ 7B ëª¨ë¸ì€ ~4GBê°€ í•„ìš”í•©ë‹ˆë‹¤.

**2. ë²•ë¥  ê³„ì•½ ë¶„ì„ (200í˜ì´ì§€, 50+ ê´€í• ê¶Œ) â†’ LLM**
- **ê¸´ ì»¨í…ìŠ¤íŠ¸**: 200í˜ì´ì§€ ê³„ì•½ì„œëŠ” 150K+ í† í°ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤; ì „ì²´ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í° ì»¨í…ìŠ¤íŠ¸ ì°½ì„ ê°€ì§„ LLMë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- **ì§€ì‹ ë²”ìœ„**: 50ê°œ ì´ìƒì˜ ê´€í• ê¶Œì— ê±¸ì¹œ ë²•ì  ì¶”ë¡ ì€ ì†Œê·œëª¨ ëª¨ë¸ì´ ë¶€ì¡±í•œ ê¹Šê³  ê´‘ë²”ìœ„í•œ ë²•ì  ì§€ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.
- **ì •í™•ì„±ì˜ ì¤‘ìš”ì„±**: ë²•ì  ì˜¤ë¥˜ëŠ” ì‹¬ê°í•œ ê²°ê³¼ë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤; íš¨ìœ¨ì„±ë³´ë‹¤ ì •í™•ì„±ì´ ìš°ì„ ì…ë‹ˆë‹¤.

**3. ì´ì»¤ë¨¸ìŠ¤ ê³ ê° ì„œë¹„ìŠ¤ â†’ SLM**
- **ì¢ì€ ë„ë©”ì¸**: í™˜ë¶ˆ, ì£¼ë¬¸ ì¶”ì , ì œí’ˆ FAQëŠ” íŒŒì¸íŠœë‹ëœ SLMì´ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì œí•œì ì´ê³  ì˜ ì •ì˜ëœ íƒœìŠ¤í¬ ë²”ìœ„ì…ë‹ˆë‹¤.
- **ë¹„ìš© ë° ì²˜ë¦¬ëŸ‰**: ê³ ê° ì„œë¹„ìŠ¤ëŠ” í•˜ë£¨ì— ìˆ˜ì²œ ê±´ì˜ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤; SLM ì¶”ë¡ ì´ í›¨ì”¬ ì €ë ´í•©ë‹ˆë‹¤.
- **íŒŒì¸íŠœë‹ ì´ì **: íšŒì‚¬ë³„ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹ëœ 7B ëª¨ë¸ì€ ì´ ì¢ì€ ë„ë©”ì¸ì—ì„œ ë²”ìš© 70B ëª¨ë¸ë³´ë‹¤ ì¢…ì¢… ë” ë›°ì–´ë‚©ë‹ˆë‹¤.

**4. ê³¼í•™ ì—°êµ¬ ì¢…í•© (500+ ë…¼ë¬¸) â†’ LLM**
- **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´**: 500ê°œ ë…¼ë¬¸ì—ì„œ ì¢…í•©í•˜ë ¤ë©´ ë§¤ìš° í° ì»¨í…ìŠ¤íŠ¸ ì°½ì´ë‚˜ ë³µì¡í•œ RAGê°€ í•„ìš”í•©ë‹ˆë‹¤; LLMì´ ë‘ ê°€ì§€ë¥¼ ë” ì˜ ì§€ì›í•©ë‹ˆë‹¤.
- **ê¹Šì€ ì¶”ë¡ **: ê³¼í•™ì  ì¢…í•©ì€ ë³µì¡í•œ ì¸ê³¼ê´€ê³„, ì‹¤í—˜ ë°©ë²•ë¡ , í†µê³„ì  ì¶”ë¡ ì˜ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤ â€” ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ í™•ì¥ë˜ëŠ” ëŠ¥ë ¥ì…ë‹ˆë‹¤.
- **ë¯¸ë¬˜í•œ í‰ê°€**: ìƒì¶©ë˜ëŠ” ë°œê²¬ ì‹ë³„ ë° í•´ê²°ì€ ê°•ë ¥í•œ ì¶”ë¡  ëŠ¥ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.

</details>

---

### ì—°ìŠµ ë¬¸ì œ 2: ì§€ì‹ ì¦ë¥˜(Knowledge Distillation) ì†ì‹¤ ì„¤ê³„

ì§€ì‹ ì¦ë¥˜ëŠ” í•™ìƒ ëª¨ë¸ì´ êµì‚¬ì˜ ë™ì‘ì„ ëª¨ë°©í•˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤. í‘œì¤€ ì¦ë¥˜ ì†ì‹¤ì€ í•˜ë“œ ë ˆì´ë¸”(ì‹¤ì œ ë‹µë³€)ê³¼ ì†Œí”„íŠ¸ ë ˆì´ë¸”(êµì‚¬ í™•ë¥ )ì„ ê²°í•©í•©ë‹ˆë‹¤:

```python
L_distill = Î± Ã— L_hard(student_logits, true_labels) +
            (1-Î±) Ã— L_soft(student_logits/T, teacher_logits/T)
```

1. ì˜¨ë„ íŒŒë¼ë¯¸í„° TëŠ” ì†Œí”„íŠ¸ ë ˆì´ë¸” ë¶„í¬ì—ì„œ ë¬´ì—‡ì„ ì œì–´í•˜ë‚˜ìš”?
2. ì¦ë¥˜ ì¤‘ T=1 ëŒ€ì‹  ë†’ì€ ì˜¨ë„(T > 1)ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
3. í•™ìŠµ ë ˆì´ë¸”ì— ë§ì¶”ëŠ” ê²ƒë³´ë‹¤ êµì‚¬ì˜ í•™ìŠµëœ ì§€ì‹ í‘œí˜„ ë³´ì¡´ì„ ìš°ì„ ì‹œí•˜ê³  ì‹¶ë‹¤ë©´ ì–´ë–¤ Î± ê°’ì„ ì„ íƒí•˜ê³ , ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

**1. ì˜¨ë„ Tê°€ ì œì–´í•˜ëŠ” ê²ƒ:**

T=1ì—ì„œ ë¶„í¬ëŠ” í‘œì¤€ ì†Œí”„íŠ¸ë§¥ìŠ¤ì…ë‹ˆë‹¤. Tê°€ ì¦ê°€í•˜ë©´ ë¶„í¬ê°€ ë” ë¶€ë“œëŸ¬ì›Œì§‘ë‹ˆë‹¤(ë” ê· ì¼). T â†’ âˆì´ë©´ ëª¨ë“  í´ë˜ìŠ¤ê°€ ë™ì¼í•œ í™•ë¥ ì„ ì–»ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, êµì‚¬ê°€ T=1ì—ì„œ [0.90, 0.09, 0.01]ì„ í• ë‹¹í•œë‹¤ë©´, T=4ì—ì„œëŠ” [0.45, 0.35, 0.20]ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â€” í´ë˜ìŠ¤ ê´€ê³„ì— ëŒ€í•œ êµì‚¬ì˜ "ë¯¿ìŒ"ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.

**2. ë†’ì€ ì˜¨ë„(T > 1)ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ :**

T=1ì—ì„œ êµì‚¬ì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ëŠ” ì¢…ì¢… ë‹¨ì¼ í´ë˜ìŠ¤ì— ì˜í•´ ì§€ë°°ë©ë‹ˆë‹¤(ì˜ˆ: 0.99, 0.01, 0.00). ì˜¤ë‹µ í´ë˜ìŠ¤ì— ëŒ€í•œ ë¹„ì œë¡œ í™•ë¥ ì€ êµì‚¬ì˜ **ë‹¤í¬ ì§€ì‹(dark knowledge)**ì„ ì¸ì½”ë”©í•©ë‹ˆë‹¤ â€” í´ë˜ìŠ¤ ê°„ ìœ ì‚¬ì„± ê´€ê³„ì— ëŒ€í•œ êµ¬ì¡°í™”ëœ ì •ë³´(ì˜ˆ: "ì´ê²ƒì€ Aì²˜ëŸ¼ ë³´ì´ì§€ë§Œ Bì™€ë„ ì•½ê°„ ìœ ì‚¬í•©ë‹ˆë‹¤"). T=1ì—ì„œ ì´ ì‹ í˜¸ëŠ” ì§€ë°°ì ì¸ í´ë˜ìŠ¤ í™•ë¥ ì— ë¬»í™ë‹ˆë‹¤. ë†’ì€ ì˜¨ë„ëŠ” ì´ëŸ¬í•œ ì‘ì€ í™•ë¥ ì„ ì¦í­í•˜ì—¬ êµì‚¬ì˜ ë‚´ë¶€ í‘œí˜„ê³¼ ìœ ì‚¬ì„± êµ¬ì¡°ì— ëŒ€í•œ ë” í’ë¶€í•œ ê·¸ë˜ë””ì–¸íŠ¸ ì‹ í˜¸ë¥¼ í•™ìƒì—ê²Œ ì œê³µí•©ë‹ˆë‹¤.

**3. êµì‚¬ ì§€ì‹ì„ ìš°ì„ ì‹œí•˜ëŠ” Î± ê°’:**

**Î±ë¥¼ 0ì— ê°€ê¹ê²Œ** ì„ íƒí•˜ì„¸ìš” (ì˜ˆ: Î± = 0.1 ë˜ëŠ” ì‹¬ì§€ì–´ 0.0).

Î±=0ì´ë©´ ì†Œí”„íŠ¸ ë ˆì´ë¸” ì†ì‹¤ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤ â€” í•™ìƒì´ ì‹¤ì œ ë ˆì´ë¸” ì°¸ì¡° ì—†ì´ ìˆœìˆ˜í•˜ê²Œ êµì‚¬ì˜ í™•ë¥  ë¶„í¬ì—ì„œ í•™ìŠµí•©ë‹ˆë‹¤. ì´ëŠ” êµì‚¬ì˜ í‘œí˜„ ì§€ì‹ ì „ë‹¬ì„ ìµœëŒ€í™”í•©ë‹ˆë‹¤.

Î±=1ì´ë©´ í•˜ë“œ ë ˆì´ë¸”ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤ â€” í‘œì¤€ ì§€ë„ í•™ìŠµì´ë©° ì¦ë¥˜ ì´ì ì´ ì—†ìŠµë‹ˆë‹¤.

ì‹¤ì œë¡œ Î±=0.1-0.3ì´ ì§€ì‹ ë³´ì¡´ì— ì¼ë°˜ì ì…ë‹ˆë‹¤. ì‘ì€ í•˜ë“œ ë ˆì´ë¸” êµ¬ì„± ìš”ì†ŒëŠ” í•™ìƒì´ ì •ë‹µì—ì„œ ë„ˆë¬´ ë©€ì–´ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³ (êµì‚¬ê°€ ì²´ê³„ì ì¸ ì˜¤ë¥˜ë¥¼ ë²”í•  ë•Œ íŠ¹íˆ ì¤‘ìš”), ì§€ë°°ì ì¸ ì†Œí”„íŠ¸ ë ˆì´ë¸” êµ¬ì„± ìš”ì†ŒëŠ” í’ë¶€í•œ í‘œí˜„ ì§€ì‹ì„ ì „ë‹¬í•©ë‹ˆë‹¤.

</details>

---

### ì—°ìŠµ ë¬¸ì œ 3: ì–‘ìí™”(Quantization) í˜•ì‹ ë¹„êµ

GPTQ, AWQ, GGUFë¥¼ ë‹¤ìŒ ì°¨ì›ì—ì„œ ë¹„êµí•˜ì„¸ìš”:

| ì°¨ì› | GPTQ | AWQ | GGUF |
|------|------|-----|------|
| ì–‘ìí™” ì ‘ê·¼ ë°©ì‹ | ? | ? | ? |
| ë³´ì • ë°ì´í„° í•„ìš” | ? | ? | ? |
| ìµœì  ì‚¬ìš© ì‚¬ë¡€ | ? | ? | ? |
| í˜¼í•© ì •ë°€ë„ ì§€ì› | ? | ? | ? |

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

| ì°¨ì› | GPTQ | AWQ | GGUF |
|------|------|-----|------|
| **ì–‘ìí™” ì ‘ê·¼ ë°©ì‹** | í—¤ì‹œì•ˆ(Hessian) ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë ˆì´ì–´ë³„ ì¬êµ¬ì„± ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” í•™ìŠµ í›„ ì–‘ìí™”(Post-training quantization). ì œê±°ëœ ê°€ì¤‘ì¹˜ì˜ ì–‘ìí™” ì˜¤ë¥˜ë¥¼ ë³´ìƒí•˜ê¸° ìœ„í•´ ë‚¨ì€ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. | í™œì„±í™” ì¸ì‹ ì–‘ìí™”(Activation-aware quantization): í° í™œì„±í™”ì™€ ê³±í•´ì§€ëŠ” ìƒìœ„ 1%ì˜ "ì¤‘ìš”í•œ" ê°€ì¤‘ì¹˜ë¥¼ ì–‘ìí™”ì—ì„œ ë³´í˜¸í•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ ê³µê²©ì ìœ¼ë¡œ ì–‘ìí™”í•©ë‹ˆë‹¤. | ë¸”ë¡ ë‹¨ìœ„ ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ì–‘ìí™” ìœ í˜•(Q4_0, Q4_K_M, Q8_0 ë“±)ì„ ì§€ì›í•˜ëŠ” í˜•ì‹ ë…ë¦½ì  ì»¨í…Œì´ë„ˆ í˜•ì‹(llama.cppì—ì„œ ì‚¬ìš©). |
| **ë³´ì • ë°ì´í„° í•„ìš”** | ì˜ˆ â€” ìµœì  ê°€ì¤‘ì¹˜ ë°˜ì˜¬ë¦¼ì„ ìœ„í•œ í—¤ì‹œì•ˆ ê³„ì‚°ì— ~128ê°œ ë³´ì • ìƒ˜í”Œì´ í•„ìš”í•©ë‹ˆë‹¤. | ì˜ˆ â€” ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ ì‹ë³„ì„ ìœ„í•œ í™œì„±í™” í†µê³„ì— ~128ê°œ ë³´ì • ìƒ˜í”Œì´ í•„ìš”í•©ë‹ˆë‹¤. | ì•„ë‹ˆìš” â€” ë³´ì • ì—†ëŠ” ì •ì  ì–‘ìí™”; ìµœì‹  í˜•ì‹(Q4_K_M)ì€ k-í‰ê·  í´ëŸ¬ìŠ¤í„°ë§ ì‚¬ìš©. |
| **ìµœì  ì‚¬ìš© ì‚¬ë¡€** | NVIDIA í•˜ë“œì›¨ì–´ì—ì„œ GPU ì¶”ë¡ ; vLLM ë˜ëŠ” HuggingFaceë¡œ ì œê³µë˜ëŠ” 4ë¹„íŠ¸ ëª¨ë¸ì— ì í•©í•©ë‹ˆë‹¤. | GPU ì¶”ë¡ ; í˜„ì €ì„± ì¸ì‹ ë³´í˜¸ë¡œ ì¸í•´ ë™ì¼í•œ ë¹„íŠ¸ í­ì—ì„œ GPTQë³´ë‹¤ ì•½ê°„ ë” ë‚˜ì€ í’ˆì§ˆì¸ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. | CPU ë° ì—£ì§€ ì¶”ë¡ (Apple Silicon, x86); Ollama ë° llama.cpp ìƒíƒœê³„ì˜ í‘œì¤€ í˜•ì‹. |
| **í˜¼í•© ì •ë°€ë„ ì§€ì›** | ì œí•œì  â€” ì¼ë°˜ì ìœ¼ë¡œ ë ˆì´ì–´ë‹¹ ê· ì¼í•œ ë¹„íŠ¸ í­. | ì˜ˆ â€” ë†’ì€ ì •ë°€ë„ë¡œ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ë¥¼ ë³´í˜¸í•¨ìœ¼ë¡œì¨ ìì—°ìŠ¤ëŸ½ê²Œ í˜¼í•© ì •ë°€ë„ ì§€ì›. | ì˜ˆ â€” GGUFëŠ” í…ì„œë³„ í˜¼í•© ì •ë°€ë„ ì§€ì›(ì˜ˆ: ì–´í…ì…˜ ê°€ì¤‘ì¹˜ëŠ” ë†’ì€ ì •ë°€ë„, FFNì€ ë‚®ì€ ì •ë°€ë„). |

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:** GPU ë°°í¬ì—ëŠ” ë” ë‚˜ì€ ì •í™•ë„-íš¨ìœ¨ì„± íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ìœ„í•´ GPTQë³´ë‹¤ AWQê°€ ì¼ë°˜ì ìœ¼ë¡œ ì„ í˜¸ë©ë‹ˆë‹¤. CPU/ì—£ì§€ ë°°í¬(Raspberry Pi, Apple M-ì¹© ë…¸íŠ¸ë¶)ì—ëŠ” llama.cppë¥¼ ì‚¬ìš©í•œ GGUFê°€ í‘œì¤€ì…ë‹ˆë‹¤.

</details>

---

### ì—°ìŠµ ë¬¸ì œ 4: "êµê³¼ì„œê°€ ì „ë¶€ë‹¤(Textbooks Are All You Need)" ë°ì´í„° ì „ëµ

Phi ê³„ì—´ì˜ SLMì€ ì›ì‹œ ì›¹ í…ìŠ¤íŠ¸ ëŒ€ì‹  ì£¼ë¡œ ê³ í’ˆì§ˆ í•©ì„± "êµê³¼ì„œ" ë°ì´í„°ë¡œ í•™ìŠµí•˜ì—¬ 1-7B íŒŒë¼ë¯¸í„° ê·œëª¨ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

1. í•©ì„± êµê³¼ì„œ ë°ì´í„°ê°€ ì†Œê·œëª¨ ëª¨ë¸ í•™ìŠµì—ì„œ ì›ì‹œ ì›¹ ë°ì´í„°ë³´ë‹¤ ë” íš¨ìœ¨ì ì¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
2. ì´ ì ‘ê·¼ ë°©ì‹ì˜ ìœ„í—˜ì„±ì´ë‚˜ í•œê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
3. ì›¹ í¬ë¡¤ë§ ë°ì´í„°ì…‹ì—ì„œ "êµê³¼ì„œì™€ ê°™ì€" ì½˜í…ì¸ ë¥¼ ì‹ë³„í•˜ëŠ” ë°ì´í„° í’ˆì§ˆ í•„í„°ë¥¼ ì–´ë–»ê²Œ ì„¤ê³„í•˜ê² ë‚˜ìš”?

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

**1. í•©ì„± êµê³¼ì„œê°€ ë” íš¨ìœ¨ì ì¸ ì´ìœ :**

- **ì •ë³´ ë°€ë„**: ì›ì‹œ ì›¹ í…ìŠ¤íŠ¸ëŠ” ê´‘ê³ , ë°˜ë³µì ì¸ ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸, SEO ìµœì í™”ëœ ì±„ìš°ê¸° ì½˜í…ì¸ , ì €í’ˆì§ˆ ì½˜í…ì¸ ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. êµê³¼ì„œëŠ” ìµœì†Œí•œì˜ ì¤‘ë³µìœ¼ë¡œ ë°€ë„ ë†’ê³  ì¡°ì§í™”ëœ êµìœ¡ì ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì§€ì‹ì„ ë‹´ìŠµë‹ˆë‹¤.
- **ì¶”ë¡  íŒ¨í„´**: êµê³¼ì„œëŠ” ë¬¸ì œ í•´ê²° ë‹¨ê³„, ì •ì˜, ì˜ˆì‹œ, ë…¼ë¦¬ì  ì§„í–‰ì„ ëª…ì‹œì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤ â€” ëª¨ë¸ì´ ì¶”ë¡ ì„ í•™ìŠµí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì •í™•í•œ íŒ¨í„´ì…ë‹ˆë‹¤.
- **ì†Œê·œëª¨ ëª¨ë¸ì€ íš¨ìœ¨ì„±ì´ í•„ìš”**: ì†Œê·œëª¨ ëª¨ë¸(1-7B)ì€ ì œí•œëœ ìš©ëŸ‰ì„ ê°€ì§‘ë‹ˆë‹¤. ê³ í’ˆì§ˆ, ê³ ë°€ë„ ì‹ í˜¸ë¡œ ë…¸ì´ì¦ˆê°€ ë§ê³  ì¤‘ë³µëœ ë°ì´í„°ë³´ë‹¤ í† í°ë‹¹ ë” ë§ì€ ê²ƒì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**2. ìœ„í—˜ì„±ê³¼ í•œê³„:**

- **í•©ì„± ë¶„í¬ ë¶ˆì¼ì¹˜**: LLM ìƒì„± í•©ì„± ë°ì´í„°ëŠ” ìì—° í…ìŠ¤íŠ¸ì™€ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì„ ê°€ì§‘ë‹ˆë‹¤ â€” ë„ˆë¬´ í˜•ì‹ì ì´ê±°ë‚˜ ë°˜ë³µì ì¸ ë¬¸êµ¬ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ìƒì„± ëª¨ë¸ì˜ í¸í–¥ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ìƒì„±ê¸° í¸í–¥ ì¦í­**: êµì‚¬ LLMì´ ì´í•´ì— ì˜¤ë¥˜ë‚˜ í¸í–¥ì´ ìˆë‹¤ë©´, í•©ì„± ë°ì´í„°ê°€ ì´ë¥¼ ì „íŒŒí•˜ê³  ì ì¬ì ìœ¼ë¡œ ì¦í­í•©ë‹ˆë‹¤.
- **ì œí•œëœ ë‹¤ì–‘ì„±**: ìˆ˜ë™ìœ¼ë¡œ íë ˆì´ì…˜ë˜ê±°ë‚˜ ìƒì„±ëœ êµê³¼ì„œëŠ” ì‹¤ì œ ë°°í¬ì— ì¤‘ìš”í•œ íŠ¹ì • ìœ í˜•ì˜ ì¶”ë¡ ì„ ê³¼ì†Œí‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **í‰ê°€ ì˜¤ì—¼**: ì¼ë°˜ ì§€ì‹ì„ í‰ê°€í•˜ë„ë¡ ì„¤ê³„ëœ ë²¤ì¹˜ë§ˆí¬ê°€ í•©ì„± í•™ìŠµ ë°ì´í„°ì™€ ê²¹ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**3. êµê³¼ì„œ í’ˆì§ˆ í•„í„° ì„¤ê³„:**

```python
def is_textbook_like(text: str) -> bool:
    signals = []

    # êµ¬ì¡°ì  ì‹ í˜¸
    has_definitions = bool(re.search(r'\b(is defined as|refers to|means that)\b', text))
    has_examples = bool(re.search(r'\b(for example|for instance|such as|e\.g\.)\b', text))
    has_steps = bool(re.search(r'\b(step [0-9]+|first,|second,|finally,)\b', text))

    # ë‚´ìš© ì‹ í˜¸
    avg_sentence_length = len(text.split()) / max(text.count('.'), 1)
    good_length = 15 < avg_sentence_length < 40  # ë„ˆë¬´ ì§§ì§€ë„ ê¸¸ì§€ë„ ì•ŠìŒ

    # í’ˆì§ˆ ì‹ í˜¸
    unique_word_ratio = len(set(text.lower().split())) / max(len(text.split()), 1)
    high_vocabulary = unique_word_ratio > 0.5

    signals = [has_definitions, has_examples, has_steps, good_length, high_vocabulary]
    return sum(signals) >= 3  # 5ê°œ ì‹ í˜¸ ì¤‘ ìµœì†Œ 3ê°œ í•„ìš”
```

ë” ì •êµí•œ ì ‘ê·¼ ë°©ì‹ì€ ì›¹ ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸ì—ì„œ Wikipedia/êµê³¼ì„œ í…ìŠ¤íŠ¸ë¥¼ êµ¬ë¶„í•˜ë„ë¡ í•™ìŠµëœ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ê°•ë ¥í•œ LLMì„ ì‚¬ìš©í•˜ì—¬ êµìœ¡ì  ê°€ì¹˜ë¥¼ ì ìˆ˜í™”í•©ë‹ˆë‹¤.

</details>
